@article{valiant1975general,
	title={General context-free recognition in less than cubic time},
	author={Valiant, Leslie G},
	journal={Journal of computer and system sciences},
	volume={10},
	number={2},
	pages={308--315},
	year={1975},
	publisher={Academic Press}
}


@article{10.1145/505241.505242,
	author = {Lee, Lillian},
	title = {Fast Context-Free Grammar Parsing Requires Fast Boolean Matrix Multiplication},
	year = {2002},
	issue_date = {January 2002},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {49},
	number = {1},
	issn = {0004-5411},
	url = {https://doi.org/10.1145/505241.505242},
	doi = {10.1145/505241.505242},
	abstract = {In 1975, Valiant showed that Boolean matrix multiplication can be used for parsing
		context-free grammars (CFGs), yielding the asympotically fastest (although not practical)
		CFG parsing algorithm known. We prove a dual result: any CFG parser with time complexity
		O(gn3-∈), where g is the size of the grammar and n is the length of the input string,
		can be efficiently converted into an algorithm to multiply m \texttimes{} m Boolean matrices
		in time O(m3-∈/3). Given that practical, substantially subcubic Boolean matrix multiplication
		algorithms have been quite difficult to find, we thus explain why there has been little
		progress in developing practical, substantially subcubic general CFG parsers. In proving
		this result, we also develop a formalization of the notion of parsing.},
	journal = {J. ACM},
	month = jan,
	pages = {1–15},
	numpages = {15},
	keywords = {Boolean matrix multiplication, context-free grammar parsing}
}

@article{abboud2018if,
	title={If the current clique algorithms are optimal, so is Valiant's parser},
	author={Abboud, Amir and Backurs, Arturs and Williams, Virginia Vassilevska},
	journal={SIAM Journal on Computing},
	volume={47},
	number={6},
	pages={2527--2555},
	year={2018},
	publisher={SIAM}
}

@article{10.1145/3186893,
	author = {Williams, Virginia Vassilevska and Williams, R. Ryan},
	title = {Subcubic Equivalences Between Path, Matrix, and Triangle Problems},
	year = {2018},
	issue_date = {September 2018},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {65},
	number = {5},
	issn = {0004-5411},
	url = {https://doi.org/10.1145/3186893},
	doi = {10.1145/3186893},
	abstract = {We say an algorithm on n \texttimes{} n matrices with integer entries in [−M,M] (or n-node graphs
		with edge weights from [−M,M]) is truly subcubic if it runs in O(n3 − δ undefined poly(log
		M)) time for some δ &gt; 0. We define a notion of subcubic reducibility and show that
		many important problems on graphs and matrices solvable in O(n3) time are equivalent
		under subcubic reductions. Namely, the following weighted problems either all have
		truly subcubic algorithms, or none of them do:•The all-pairs shortest paths problem
		on weighted digraphs (APSP).•Detecting if a weighted graph has a triangle of negative
		total edge weight.•Listing up to n2.99 negative triangles in an edge-weighted graph.•Finding
		a minimum weight cycle in a graph of non-negative edge weights.•The replacement paths
		problem on weighted digraphs.•Finding the second shortest simple path between two
		nodes in a weighted digraph.•Checking whether a given matrix defines a metric.•Verifying
		the correctness of a matrix product over the (min, +)-semiring.•Finding a maximum
		subarray in a given matrix.Therefore, if APSP cannot be solved in n3−ε time for any
		ε &gt; 0, then many other problems also need essentially cubic time. In fact, we show
		generic equivalences between matrix products over a large class of algebraic structures
		used in optimization, verifying a matrix product over the same structure, and corresponding
		triangle detection problems over the structure. These equivalences simplify prior
		work on subcubic algorithms for all-pairs path problems, since it now suffices to
		give appropriate subcubic triangle detection algorithms.Other consequences of our
		work are new combinatorial approaches to Boolean matrix multiplication over the (OR,AND)-semiring
		(abbreviated as BMM). We show that practical advances in triangle detection would
		imply practical BMM algorithms, among other results. Building on our techniques, we
		give two improved BMM algorithms: a derandomization of the combinatorial BMM algorithm
		of Bansal and Williams (FOCS’09), and an improved quantum algorithm for BMM.},
	journal = {J. ACM},
	month = aug,
	articleno = {27},
	numpages = {38},
	keywords = {all-pairs shortest paths, subcubic time, fine-grained reductions, Fine-grained complexity, equivalences}
}

@inproceedings{10.5555/646233.682379,
	author = {Ruzzo, Walter L.},
	title = {On the Complexity of General Context-Free Language Parsing and Recognition (Extended Abstract)},
	year = {1979},
	isbn = {3540095101},
	publisher = {Springer-Verlag},
	address = {Berlin, Heidelberg},
	booktitle = {Proceedings of the 6th Colloquium, on Automata, Languages and Programming},
	pages = {489–497},
	numpages = {9}
}

@article{10.1016/j.tcs.2004.05.009,
	author = {Eisenbrand, Friedrich and Grandoni, Fabrizio},
	title = {On the Complexity of Fixed Parameter Clique and Dominating Set},
	year = {2004},
	issue_date = {20 October 2004},
	publisher = {Elsevier Science Publishers Ltd.},
	address = {GBR},
	volume = {326},
	number = {1–3},
	issn = {0304-3975},
	url = {https://doi.org/10.1016/j.tcs.2004.05.009},
	doi = {10.1016/j.tcs.2004.05.009},
	abstract = {We provide simple, faster algorithms for the detection of cliques and dominating sets
		of fixed order. Our algorithms are based on reductions to rectangular matrix multiplication.
		We also describe an improved algorithm for diamonds detection.},
	journal = {Theor. Comput. Sci.},
	month = oct,
	pages = {57–67},
	numpages = {11},
	keywords = {parameterized algorithms, dominating set, diamonds detection, clique}
}

@article{nevsetvril1985complexity,
	title={On the complexity of the subgraph problem},
	author={Ne{\v{s}}et{\v{r}}il, Jaroslav and Poljak, Svatopluk},
	journal={Commentationes Mathematicae Universitatis Carolinae},
	volume={26},
	number={2},
	pages={415--419},
	year={1985},
	publisher={Charles University in Prague, Faculty of Mathematics and Physics}
}

@article{10.1145/3158118,
	author = {Chatterjee, Krishnendu and Choudhary, Bhavya and Pavlogiannis, Andreas},
	title = {Optimal Dyck Reachability for Data-Dependence and Alias Analysis},
	year = {2017},
	issue_date = {January 2018},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {2},
	number = {POPL},
	url = {https://doi.org/10.1145/3158118},
	doi = {10.1145/3158118},
	abstract = {A fundamental algorithmic problem at the heart of static analysis is Dyck reachability.
		The input is a graph where the edges are labeled with different types of opening and
		closing parentheses, and the reachability information is computed via paths whose
		parentheses are properly matched. We present new results for Dyck reachability problems
		with applications to alias analysis and data-dependence analysis. Our main contributions,
		that include improved upper bounds as well as lower bounds that establish optimality
		guarantees, are as follows: First, we consider Dyck reachability on bidirected graphs,
		which is the standard way of performing field-sensitive points-to analysis. Given
		a bidirected graph with n nodes and m edges, we present: (i)&nbsp;an algorithm with worst-case
		running time O(m + n · α(n)), where α(n) is the inverse Ackermann function, improving
		the previously known O(n2) time bound; (ii)&nbsp;a matching lower bound that shows that
		our algorithm is optimal wrt to worst-case complexity; and (iii)&nbsp;an optimal average-case
		upper bound of O(m) time, improving the previously known O(m · logn) bound. Second,
		we consider the problem of context-sensitive data-dependence analysis, where the task
		is to obtain analysis summaries of library code in the presence of callbacks. Our
		algorithm preprocesses libraries in almost linear time, after which the contribution
		of the library in the complexity of the client analysis is only linear, and only wrt
		the number of call sites. Third, we prove that combinatorial algorithms for Dyck reachability
		on general graphs with truly sub-cubic bounds cannot be obtained without obtaining
		sub-cubic combinatorial algorithms for Boolean Matrix Multiplication, which is a long-standing
		open problem. Thus we establish that the existing combinatorial algorithms for Dyck
		reachability are (conditionally) optimal for general graphs. We also show that the
		same hardness holds for graphs of constant treewidth. Finally, we provide a prototype
		implementation of our algorithms for both alias analysis and data-dependence analysis.
		Our experimental evaluation demonstrates that the new algorithms significantly outperform
		all existing methods on the two problems, over real-world benchmarks.},
	journal = {Proc. ACM Program. Lang.},
	month = dec,
	articleno = {30},
	numpages = {30},
	keywords = {Bidirected graphs, treewidth, CFL reachability, Data-dependence analysis, Dyck reachability}
}

@inbook{inbook,
	author = {Orachev, Egor and Epelbaum, Ilya and Azimov, Rustam and Grigorev, Semyon},
	year = {2020},
	month = {08},
	pages = {49-59},
	title = {Context-Free Path Querying by Kronecker Product},
	isbn = {978-3-030-54831-5},
	doi = {10.1007/978-3-030-54832-2_6}
}

@inproceedings{10.1109/FOCS.2014.53,
	author = {Abboud, Amir and Williams, Virginia Vassilevska},
	title = {Popular Conjectures Imply Strong Lower Bounds for Dynamic Problems},
	year = {2014},
	isbn = {9781479965175},
	publisher = {IEEE Computer Society},
	address = {USA},
	url = {https://doi.org/10.1109/FOCS.2014.53},
	doi = {10.1109/FOCS.2014.53},
	abstract = {We consider several well-studied problems in dynamic algorithms and prove that sufficient
		progress on any of them would imply a breakthrough on one of five major open problems
		in the theory of algorithms: 1) Is the 3SUM problem on n numbers in O(n2 -- \'{y}) time
		for some \'{y} &gt; 0__ __ 2) Can one determine the satisfiability of a CNF formula on n
		variables and poly n clauses in O((2 -- \'{y})npolyn) time for some \'{y} &gt; 0__ __ 3) Is the
		All Pairs Shortest Paths problem for graphs on n vertices in O(n3 -- \'{y}) time for some
		\'{y} &gt; 0__ __ 4) Is there a linear time algorithm that detects whether a given graph
		contains a triangle__ __ 5) Is there an O(n3 -- \'{y}) time combinatorial algorithm for
		n n Boolean matrix multiplication__ __ The problems we consider include dynamic versions
		of bipartite perfect matching, bipartite maximum weight matching, single source reachability,
		single source shortest paths, strong connectivity, subgraph connectivity, diameter
		approximation and some nongraph problems such as Pagh's problem defined in a recent
		paper by p\u{a}tra\c{s}cu [STOC 2010].},
	booktitle = {Proceedings of the 2014 IEEE 55th Annual Symposium on Foundations of Computer Science},
	pages = {434–443},
	numpages = {10},
	keywords = {3SUM, dynamic algorithms, lower bounds, all pairs shortest paths},
	series = {FOCS '14}
}

@inproceedings{bradford2017efficient,
	title={Efficient exact paths for Dyck and semi-Dyck labeled path reachability},
	author={Bradford, Phillip G},
	booktitle={2017 IEEE 8th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference (UEMCON)},
	pages={247--253},
	year={2017},
	organization={IEEE}
}

@article{10.1145/3434315,
	author = {Mathiasen, Anders Alnor and Pavlogiannis, Andreas},
	title = {The Fine-Grained and Parallel Complexity of Andersen’s Pointer Analysis},
	year = {2021},
	issue_date = {January 2021},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {5},
	number = {POPL},
	url = {https://doi.org/10.1145/3434315},
	doi = {10.1145/3434315},
	abstract = {Pointer analysis is one of the fundamental problems in static program analysis. Given
	a set of pointers, the task is to produce a useful over-approximation of the memory
	locations that each pointer may point-to at runtime. The most common formulation is
	Andersen’s Pointer Analysis (APA), defined as an inclusion-based set of m pointer
	constraints over a set of n pointers. Scalability is extremely important, as points-to
	information is a prerequisite to many other components in the static-analysis pipeline.
	Existing algorithms solve APA in O(n2· m) time, while it has been conjectured that
	the problem has no truly sub-cubic algorithm, with a proof so far having remained
	elusive. It is also well-known that APA can be solved in O(n2) time under certain
	sparsity conditions that hold naturally in some settings. Besides these simple bounds,
	the complexity of the problem has remained poorly understood. In this work we draw
	a rich fine-grained and parallel complexity landscape of APA, and present upper and
	lower bounds. First, we establish an O(n3) upper-bound for general APA, improving
	over O(n2· m) as n=O(m). Second, we show that even on-demand APA (“may a specific
	pointer a point to a specific location b?”) has an Ω(n3) (combinatorial) lower bound
	under standard complexity-theoretic hypotheses. This formally establishes the long-conjectured
	“cubic bottleneck” of APA, and shows that our O(n3)-time algorithm is optimal. Third,
	we show that under mild restrictions, APA is solvable in \~{O}(nω) time, where ω&lt;2.373
	is the matrix-multiplication exponent. It is believed that ω=2+o(1), in which case
	this bound becomes quadratic. Fourth, we show that even under such restrictions, even
	the on-demand problem has an Ω(n2) lower bound under standard complexity-theoretic
	hypotheses, and hence our algorithm is optimal when ω=2+o(1). Fifth, we study the
	parallelizability of APA and establish lower and upper bounds: (i) in general, the
	problem is P-complete and hence unlikely parallelizable, whereas (ii) under mild restrictions,
	the problem is parallelizable. Our theoretical treatment formalizes several insights
	that can lead to practical improvements in the future.},
	journal = {Proc. ACM Program. Lang.},
	month = jan,
	articleno = {34},
	numpages = {29},
	keywords = {fine-grained complexity, inclusion-based pointer analysis, Dyck reachability, static pointer analysis}
}

@inproceedings{10.5555/788019.788876,
	author = {Heintze, Nevin and McAllester, David},
	title = {On the Cubic Bottleneck in Subtyping and Flow Analysis},
	year = {1997},
	isbn = {0818679255},
	publisher = {IEEE Computer Society},
	address = {USA},
	abstract = {We prove that certain data-flow and control-flow problems are 2NPDA-complete. This
	means that these problems are in the class 2NPDA and that they are hard for that class.
	The fact that they are in 2NPDA demonstrates the richness of the class. The fact that
	they are hard for 2NPDA can be interpreted as evidence they can not be solved in sub-cubic
	time --- the cubic time decision procedure for an arbitrary 2NPDA problem has not
	been improved since its discovery in 1968.},
	booktitle = {Proceedings of the 12th Annual IEEE Symposium on Logic in Computer Science},
	pages = {342},
	series = {LICS '97}
}

@inproceedings{10.1145/2840728.2840746,
	author = {Carmosino, Marco L. and Gao, Jiawei and Impagliazzo, Russell and Mihajlin, Ivan and Paturi, Ramamohan and Schneider, Stefan},
	title = {Nondeterministic Extensions of the Strong Exponential Time Hypothesis and Consequences for Non-Reducibility},
	year = {2016},
	isbn = {9781450340571},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2840728.2840746},
	doi = {10.1145/2840728.2840746},
	abstract = {We introduce the Nondeterministic Strong Exponential Time Hypothesis (NSETH) as a
	natural extension of the Strong Exponential Time Hypothesis (SETH). We show that both
	refuting and proving NSETH would have interesting consequences.In particular we show
	that disproving NSETH would give new nontrivial circuit lower bounds. On the other
	hand, NSETH implies non-reducibility results, i.e. the absence of (deterministic)
	fine-grained reductions from SAT to a number of problems. As a consequence we conclude
	that unless this hypothesis fails, problems such as 3-SUM, APSP and model checking
	of a large class of first-order graph properties cannot be shown to be SETH-hard using
	deterministic or zero-error probabilistic reductions.},
	booktitle = {Proceedings of the 2016 ACM Conference on Innovations in Theoretical Computer Science},
	pages = {261–270},
	numpages = {10},
	keywords = {computational complexity, conditional lower bounds, 3-sum, nondeterminism, fine-grained complexity, all-pairs shortest path, seth},
	location = {Cambridge, Massachusetts, USA},
	series = {ITCS '16}
}

@article{Hanauer2020FasterFD,
	title={Faster Fully Dynamic Transitive Closure in Practice},
	author={Kathrin Hanauer and Monika Henzinger and Christian Schulz},
	journal={ArXiv},
	year={2020},
	volume={abs/2002.00813}
}

@article{10.1145/258994.259006,
	author = {Melski, David and Reps, Thomas},
	title = {Interconvertbility of Set Constraints and Context-Free Language Reachability},
	year = {1997},
	issue_date = {Dec. 1997},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {32},
	number = {12},
	issn = {0362-1340},
	url = {https://doi.org/10.1145/258994.259006},
	doi = {10.1145/258994.259006},
	abstract = {We show the interconvertibility of context-free-language reachability problems and
	a class of set-constraint problems: given a context-free-language reachability problem,
	we show how to construct a set-constraint problem whose answer gives a solution to
	the reachability problem; given a set-constraint problem, we show how to construct
	a context-free-language reachability problem whose answer gives a solution to the
	set-constraint problem. The interconvertibility of these two formalisms offers an
	conceptual advantage akin to the advantage gained from the interconvertibility of
	finite-state automata and regular expressions in formal language theory, namely, a
	problem can be formulated in whichever formalism is most natural. It also offers some
	insight into the "O(n3) bottleneck" for different types of program-analysis problems,
	and allows results previously obtained for context-free-language reachability problems
	to be applied to set-constraint problems.},
	journal = {SIGPLAN Not.},
	month = dec,
	pages = {74–89},
	numpages = {16}
}

@inproceedings{bringmann2019fine,
	title={Fine-Grained Complexity Theory},
	author={Bringmann, Karl},
	booktitle={36th International Symposium on Theoretical Aspects of Computer Science},
	pages={1},
	year={2019}
}

@inproceedings{10.1145/360204.360208,
	author = {Rehof, Jakob and F\"{a}hndrich, Manuel},
	title = {Type-Base Flow Analysis: From Polymorphic Subtyping to CFL-Reachability},
	year = {2001},
	isbn = {1581133367},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/360204.360208},
	doi = {10.1145/360204.360208},
	abstract = {We present a novel approach to scalable implementation of type-based flow analysis
	with polymorphic subtyping. Using a new presentation of polymorphic subytping with
	instantiation constraints, we are able to apply context-free language (CFL) reachability
	techniques to type-based flow analysis. We develop a CFL-based algorithm for computing
	flow-information in time O(n³), where n is the size of the typed program. The
	algorithm substantially improves upon the best previously known algorithm for flow
	analysis based on polymorphic subtyping with complexity O(n8). Our technique also
	yields the first demand-driven algorithm for polymorphic subtype-based flow-computation.
	It works directly on higher-order programs with structured data of finite type (unbounded
	data structures are incorporated via finite approximations), supports context-sensitive,
	global flow summariztion and includes polymorphic recursion.},
	booktitle = {Proceedings of the 28th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
	pages = {54–66},
	numpages = {13},
	location = {London, United Kingdom},
	series = {POPL '01}
}

@article{10.1145/373243.360208,
	author = {Rehof, Jakob and F\"{a}hndrich, Manuel},
	title = {Type-Base Flow Analysis: From Polymorphic Subtyping to CFL-Reachability},
	year = {2001},
	issue_date = {March 2001},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {36},
	number = {3},
	issn = {0362-1340},
	url = {https://doi.org/10.1145/373243.360208},
	doi = {10.1145/373243.360208},
	abstract = {We present a novel approach to scalable implementation of type-based flow analysis
	with polymorphic subtyping. Using a new presentation of polymorphic subytping with
	instantiation constraints, we are able to apply context-free language (CFL) reachability
	techniques to type-based flow analysis. We develop a CFL-based algorithm for computing
	flow-information in time O(n³), where n is the size of the typed program. The
	algorithm substantially improves upon the best previously known algorithm for flow
	analysis based on polymorphic subtyping with complexity O(n8). Our technique also
	yields the first demand-driven algorithm for polymorphic subtype-based flow-computation.
	It works directly on higher-order programs with structured data of finite type (unbounded
	data structures are incorporated via finite approximations), supports context-sensitive,
	global flow summariztion and includes polymorphic recursion.},
	journal = {SIGPLAN Not.},
	month = jan,
	pages = {54–66},
	numpages = {13}
}

@inproceedings{10.1145/1094811.1094817,
	author = {Sridharan, Manu and Gopan, Denis and Shan, Lexin and Bod\'{\i}k, Rastislav},
	title = {Demand-Driven Points-to Analysis for Java},
	year = {2005},
	isbn = {1595930310},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1094811.1094817},
	doi = {10.1145/1094811.1094817},
	abstract = {We present a points-to analysis technique suitable for environments with small time
	and memory budgets, such as just-in-time (JIT) compilers and interactive development
	environments (IDEs). Our technique is demand-driven, performing only the work necessary
	to answer each query (a request for a variable's points-to information) issued by
	a client. In cases where even the demand-driven approach exceeds the time budget for
	a query, we employ early termination, i.e., stopping the analysis prematurely and
	returning an over-approximated result to the client. Our technique improves on previous
	demand-driven points-to analysis algorithms [17, 33] by achieving much higher precision
	under small time budgets and early termination.We formulate Andersen's analysis [5]
	for Java as a CFL-reachability problem [33]. This formulation shows that Andersen's
	analysis for Java is a balanced-parentheses problem, an insight that enables our new
	techniques. We exploit the balanced parentheses structure to approximate Andersen's
	analysis by regularizing the CFL-reachability problem, yielding an asymptotically
	cheaper algorithm. We also show how to regain most of the precision lost in the regular
	approximation as needed through refinement. Our evaluation shows that our regularization
	and refinement approach achieves nearly the precision of field-sensitive Andersen's
	analysis in time budgets as small as 2ms per query. Our technique can yield speedups
	of up to 16x over computing an exhaustive Andersen's analysis for some clients, with
	little to no precision loss.},
	booktitle = {Proceedings of the 20th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications},
	pages = {59–76},
	numpages = {18},
	keywords = {points-to analysis, context-free language reachability, refinement, demand-driven analysis},
	location = {San Diego, CA, USA},
	series = {OOPSLA '05}
}

@article{10.1145/1103845.1094817,
	author = {Sridharan, Manu and Gopan, Denis and Shan, Lexin and Bod\'{\i}k, Rastislav},
	title = {Demand-Driven Points-to Analysis for Java},
	year = {2005},
	issue_date = {October 2005},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {40},
	number = {10},
	issn = {0362-1340},
	url = {https://doi.org/10.1145/1103845.1094817},
	doi = {10.1145/1103845.1094817},
	abstract = {We present a points-to analysis technique suitable for environments with small time
	and memory budgets, such as just-in-time (JIT) compilers and interactive development
	environments (IDEs). Our technique is demand-driven, performing only the work necessary
	to answer each query (a request for a variable's points-to information) issued by
	a client. In cases where even the demand-driven approach exceeds the time budget for
	a query, we employ early termination, i.e., stopping the analysis prematurely and
	returning an over-approximated result to the client. Our technique improves on previous
	demand-driven points-to analysis algorithms [17, 33] by achieving much higher precision
	under small time budgets and early termination.We formulate Andersen's analysis [5]
	for Java as a CFL-reachability problem [33]. This formulation shows that Andersen's
	analysis for Java is a balanced-parentheses problem, an insight that enables our new
	techniques. We exploit the balanced parentheses structure to approximate Andersen's
	analysis by regularizing the CFL-reachability problem, yielding an asymptotically
	cheaper algorithm. We also show how to regain most of the precision lost in the regular
	approximation as needed through refinement. Our evaluation shows that our regularization
	and refinement approach achieves nearly the precision of field-sensitive Andersen's
	analysis in time budgets as small as 2ms per query. Our technique can yield speedups
	of up to 16x over computing an exhaustive Andersen's analysis for some clients, with
	little to no precision loss.},
	journal = {SIGPLAN Not.},
	month = oct,
	pages = {59–76},
	numpages = {18},
	keywords = {points-to analysis, refinement, context-free language reachability, demand-driven analysis}
}


@inproceedings{10.1145/1133981.1134027,
	author = {Sridharan, Manu and Bod\'{\i}k, Rastislav},
	title = {Refinement-Based Context-Sensitive Points-to Analysis for Java},
	year = {2006},
	isbn = {1595933204},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1133981.1134027},
	doi = {10.1145/1133981.1134027},
	abstract = {We present a scalable and precise context-sensitive points-to analysis with three
	key properties: (1) filtering out of unrealizable paths, (2) a context-sensitive heap
	abstraction, and (3) a context-sensitive call graph. Previous work [21] has shown
	that all three properties are important for precisely analyzing large programs, e.g.,
	to show safety of downcasts. Existing analyses typically give up one or more of the
	properties for scalability. We have developed a refinement-based analysis that succeeds
	by simultaneously refining handling of method calls and heap accesses, allowing the
	analysis to precisely analyze important code while entirely skipping irrelevant code.
	The analysis is demanddriven and client-driven, facilitating refinement specific to
	each queried variable and increasing scalability. In our experimental evaluation,
	our analysis proved the safety of 61% more casts than one of the most precise existing
	analyses across a suite of large benchmarks. The analysis checked the casts in under
	13 minutes per benchmark (taking less than 1 second per query) and required only 35MB
	of memory, far less than previous approaches.},
	booktitle = {Proceedings of the 27th ACM SIGPLAN Conference on Programming Language Design and Implementation},
	pages = {387–400},
	numpages = {14},
	keywords = {demand-driven analysis, context-sensitive analysis, points-to analysis, refinement},
	location = {Ottawa, Ontario, Canada},
	series = {PLDI '06}
}

@article{10.1145/1133255.1134027,
	author = {Sridharan, Manu and Bod\'{\i}k, Rastislav},
	title = {Refinement-Based Context-Sensitive Points-to Analysis for Java},
	year = {2006},
	issue_date = {June 2006},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {41},
	number = {6},
	issn = {0362-1340},
	url = {https://doi.org/10.1145/1133255.1134027},
	doi = {10.1145/1133255.1134027},
	abstract = {We present a scalable and precise context-sensitive points-to analysis with three
	key properties: (1) filtering out of unrealizable paths, (2) a context-sensitive heap
	abstraction, and (3) a context-sensitive call graph. Previous work [21] has shown
	that all three properties are important for precisely analyzing large programs, e.g.,
	to show safety of downcasts. Existing analyses typically give up one or more of the
	properties for scalability. We have developed a refinement-based analysis that succeeds
	by simultaneously refining handling of method calls and heap accesses, allowing the
	analysis to precisely analyze important code while entirely skipping irrelevant code.
	The analysis is demanddriven and client-driven, facilitating refinement specific to
	each queried variable and increasing scalability. In our experimental evaluation,
	our analysis proved the safety of 61% more casts than one of the most precise existing
	analyses across a suite of large benchmarks. The analysis checked the casts in under
	13 minutes per benchmark (taking less than 1 second per query) and required only 35MB
	of memory, far less than previous approaches.},
	journal = {SIGPLAN Not.},
	month = jun,
	pages = {387–400},
	numpages = {14},
	keywords = {context-sensitive analysis, demand-driven analysis, points-to analysis, refinement}
}


@inproceedings{10.1145/298514.298576,
	author = {Yannakakis, Mihalis},
	title = {Graph-Theoretic Methods in Database Theory},
	year = {1990},
	isbn = {0897913523},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/298514.298576},
	doi = {10.1145/298514.298576},
	booktitle = {Proceedings of the Ninth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems},
	pages = {230–242},
	numpages = {13},
	location = {Nashville, Tennessee, USA},
	series = {PODS '90}
}

@inproceedings{10.1145/1328438.1328460,
	author = {Chaudhuri, Swarat},
	title = {Subcubic Algorithms for Recursive State Machines},
	year = {2008},
	isbn = {9781595936899},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1328438.1328460},
	doi = {10.1145/1328438.1328460},
	abstract = {We show that the reachability problem for recursive state machines (or equivalently,
	pushdown systems), believed for long to have cubic worst-case complexity, can be solved
	in slightly subcubic time. All that is necessary for the new bound is a simple adaptation
	of a known technique. We also show that a better algorithm exists if the input machine
	does not have infinite recursive loops.},
	booktitle = {Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
	pages = {159–169},
	numpages = {11},
	keywords = {transitive closure, CFL-reachability, interprocedural analysis, context-free languages, cubic bottleneck, recursive state machines, pushdown systems},
	location = {San Francisco, California, USA},
	series = {POPL '08}
}

@inproceedings{10.1145/199448.199462,
	author = {Reps, Thomas and Horwitz, Susan and Sagiv, Mooly},
	title = {Precise Interprocedural Dataflow Analysis via Graph Reachability},
	year = {1995},
	isbn = {0897916921},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/199448.199462},
	doi = {10.1145/199448.199462},
	abstract = {The paper shows how a large class of interprocedural dataflow-analysis problems can
	be solved precisely in polynomial time by transforming them into a special kind of
	graph-reachability problem. The only restrictions are that the set of dataflow facts
	must be a finite set, and that the dataflow functions must distribute over the confluence
	operator (either union or intersection). This class of probable problems includes—but
	is not limited to—the classical separable problems (also known as “gen/kill” or “bit-vector”
	problems)—e.g., reaching definitions, available expressions, and live variables. In
	addition, the class of problems that our techniques handle includes many non-separable
	problems, including truly-live variables, copy constant propagation, and possibly-uninitialized
	variables.Results are reported from a preliminary experimental study of C programs
	(for the problem of finding possibly-uninitialized variables).},
	booktitle = {Proceedings of the 22nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
	pages = {49–61},
	numpages = {13},
	location = {San Francisco, California, USA},
	series = {POPL '95}
}

@inproceedings{10.5555/3039686.3039828,
	author = {Larsen, Kasper Green and Williams, Ryan},
	title = {Faster Online Matrix-Vector Multiplication},
	year = {2017},
	publisher = {Society for Industrial and Applied Mathematics},
	address = {USA},
	abstract = {We consider the Online Boolean Matrix-Vector Multiplication (OMV) problem studied
	by Henzinger et al. [STOC'15]: given an n \texttimes{} n Boolean matrix M, we receive n Boolean
	vectors v1,...,vn one at a time, and are required to output Mvi (over the Boolean
	semiring) before seeing the vector vi+1, for all i. Previous known algorithms for
	this problem are combinatorial, running in O(n3 /log2 n) time. Henzinger et al. conjecture
	there is no O(n3−ε) time algorithm for OMV, for all ε &gt; 0; their OMV conjecture is
	shown to imply strong hardness results for many basic dynamic problems.We give a substantially
	faster method for computing OMV, running in [EQUATION] randomized time. In fact, after
	seeing [EQUATION] vectors, we already achieve [EQUATION] amortized time for matrix-vector
	multiplication. Our approach gives a way to reduce matrix-vector multiplication to
	solving a version of the Orthogonal Vectors problem, which in turn reduces to "small"
	algebraic matrix-matrix multiplication. Applications include faster independent set
	detection, partial match retrieval, and 2-CNF evaluation.We also show how a modification
	of our method gives a cell probe data structure for OMV with worst case [EQUATION]
	time per query vector, where w is the word size. This result rules out an unconditional
	proof of the OMV conjecture using purely information-theoretic arguments.},
	booktitle = {Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms},
	pages = {2182–2189},
	numpages = {8},
	location = {Barcelona, Spain},
	series = {SODA '17}
}

@inproceedings{10.1145/2746539.2746609,
	author = {Henzinger, Monika and Krinninger, Sebastian and Nanongkai, Danupon and Saranurak, Thatchaphol},
	title = {Unifying and Strengthening Hardness for Dynamic Problems via the Online Matrix-Vector Multiplication Conjecture},
	year = {2015},
	isbn = {9781450335362},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2746539.2746609},
	doi = {10.1145/2746539.2746609},
	abstract = {Consider the following Online Boolean Matrix-Vector Multiplication problem: We are
	given an n x n matrix M and will receive n column-vectors of size n, denoted by v1,
	..., vn, one by one. After seeing each vector vi, we have to output the product Mvi
	before we can see the next vector. A naive algorithm can solve this problem using
	O(n3) time in total, and its running time can be slightly improved to O(n3/log2 n)
	[Williams SODA'07]. We show that a conjecture that there is no truly subcubic (O(n3-ε))
	time algorithm for this problem can be used to exhibit the underlying polynomial time
	hardness shared by many dynamic problems. For a number of problems, such as subgraph
	connectivity, Pagh's problem, d-failure connectivity, decremental single-source shortest
	paths, and decremental transitive closure, this conjecture implies tight hardness
	results. Thus, proving or disproving this conjecture will be very interesting as it
	will either imply several tight unconditional lower bounds or break through a common
	barrier that blocks progress with these problems. This conjecture might also be considered
	as strong evidence against any further improvement for these problems since refuting
	it will imply a major breakthrough for combinatorial Boolean matrix multiplication
	and other long-standing problems if the term "combinatorial algorithms" is interpreted
	as "Strassen-like algorithms" [Ballard et al. SPAA'11].The conjecture also leads to
	hardness results for problems that were previously based on diverse problems and conjectures
	-- such as 3SUM, combinatorial Boolean matrix multiplication, triangle detection,
	and multiphase -- thus providing a uniform way to prove polynomial hardness results
	for dynamic algorithms; some of the new proofs are also simpler or even become trivial.
	The conjecture also leads to stronger and new, non-trivial, hardness results, e.g.,
	for the fully-dynamic densest subgraph and diameter problems.},
	booktitle = {Proceedings of the Forty-Seventh Annual ACM Symposium on Theory of Computing},
	pages = {21–30},
	numpages = {10},
	keywords = {lower bounds, dynamic graph algorithms},
	location = {Portland, Oregon, USA},
	series = {STOC '15}
}

@misc{shemetova2021algorithm,
	title={One Algorithm to Evaluate Them All: Unified Linear Algebra Based Approach to Evaluate Both Regular and Context-Free Path Queries}, 
	author={Ekaterina Shemetova and Rustam Azimov and Egor Orachev and Ilya Epelbaum and Semyon Grigorev},
	year={2021},
	eprint={2103.14688},
	archivePrefix={arXiv},
	primaryClass={cs.DB}
}

@INPROCEEDINGS{8948597,  
	author={van den Brand, Jan and Nanongkai, Danupon and Saranurak, Thatchaphol},  
	booktitle={2019 IEEE 60th Annual Symposium on Foundations of Computer Science (FOCS)},   
	title={Dynamic Matrix Inverse: Improved Algorithms and Matching Conditional Lower Bounds},   
	year={2019},  
	volume={},  
	number={},  
	pages={456-480},  
	doi={10.1109/FOCS.2019.00036}}

@article{REPS1998701,
	title = {Program analysis via graph reachability1An abbreviated version of this paper appeared as an invited paper in the Proceedings of the 1997 International Symposium on Logic Programming [84].1},
	journal = {Information and Software Technology},
	volume = {40},
	number = {11},
	pages = {701-726},
	year = {1998},
	issn = {0950-5849},
	doi = {https://doi.org/10.1016/S0950-5849(98)00093-7},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584998000937},
	author = {Thomas Reps},
	abstract = {This paper describes how a number of program-analysis problems can be solved by transforming them to graph-reachability problems. Some of the program-analysis problems that are amenable to this treatment include program slicing, certain dataflow-analysis problems, one version of the problem of approximating the possible “shapes” that heap-allocated structures in a program can take on, and flow-insensitive points-to analysis. Relationships between graph reachability and other approaches to program analysis are described. Some techniques that go beyond pure graph reachability are also discussed.}
}

@article { SubgraphQueriesbyContextfreeGrammars,
      author = "Petteri Sevon and Lauri Eronen",
      title = "Subgraph Queries by Context-free Grammars",
      journal = "Journal of Integrative Bioinformatics",
      year = "2008",
      publisher = "De Gruyter",
      address = "Berlin, Boston",
      volume = "5",
      number = "2",
      doi = "https://doi.org/10.1515/jib-2008-100",
      pages=      "157 -- 172",
      url = "https://www.degruyter.com/view/journals/jib/5/2/article-p157.xml"
}

@article{hansen2021tight,
  title={Tight bounds for reachability problems on one-counter and pushdown systems},
  author={Hansen, Jakob Cetti and Kjelstr{\o}m, Adam Husted and Pavlogiannis, Andreas},
  journal={Information Processing Letters},
  volume={171},
  pages={106135},
  year={2021},
  publisher={Elsevier}
}

@article{Sato2017ALA,
  title={A linear algebraic approach to datalog evaluation},
  author={Taisuke Sato},
  journal={Theory and Practice of Logic Programming},
  year={2017},
  volume={17},
  pages={244 - 265}
}

@inproceedings{10.1145/258993.259006,
author = {Melski, David and Reps, Thomas},
title = {Interconvertbility of Set Constraints and Context-Free Language Reachability},
year = {1997},
isbn = {0897919173},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/258993.259006},
doi = {10.1145/258993.259006},
abstract = {We show the interconvertibility of context-free-language reachability problems and a class of set-constraint problems: given a context-free-language reachability problem, we show how to construct a set-constraint problem whose answer gives a solution to the reachability problem; given a set-constraint problem, we show how to construct a context-free-language reachability problem whose answer gives a solution to the set-constraint problem. The interconvertibility of these two formalisms offers an conceptual advantage akin to the advantage gained from the interconvertibility of finite-state automata and regular expressions in formal language theory, namely, a problem can be formulated in whichever formalism is most natural. It also offers some insight into the "O(n3) bottleneck" for different types of program-analysis problems, and allows results previously obtained for context-free-language reachability problems to be applied to set-constraint problems.},
booktitle = {Proceedings of the 1997 ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation},
pages = {74–89},
numpages = {16},
location = {Amsterdam, The Netherlands},
series = {PEPM '97}
}

@article{10.1145/258994.259006,
author = {Melski, David and Reps, Thomas},
title = {Interconvertbility of Set Constraints and Context-Free Language Reachability},
year = {1997},
issue_date = {Dec. 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {12},
issn = {0362-1340},
url = {https://doi.org/10.1145/258994.259006},
doi = {10.1145/258994.259006},
abstract = {We show the interconvertibility of context-free-language reachability problems and a class of set-constraint problems: given a context-free-language reachability problem, we show how to construct a set-constraint problem whose answer gives a solution to the reachability problem; given a set-constraint problem, we show how to construct a context-free-language reachability problem whose answer gives a solution to the set-constraint problem. The interconvertibility of these two formalisms offers an conceptual advantage akin to the advantage gained from the interconvertibility of finite-state automata and regular expressions in formal language theory, namely, a problem can be formulated in whichever formalism is most natural. It also offers some insight into the "O(n3) bottleneck" for different types of program-analysis problems, and allows results previously obtained for context-free-language reachability problems to be applied to set-constraint problems.},
journal = {SIGPLAN Not.},
month = {dec},
pages = {74–89},
numpages = {16}
}

@book{10.5555/524279,
author = {Sipser, Michael},
title = {Introduction to the Theory of Computation},
year = {1996},
isbn = {053494728X},
publisher = {International Thomson Publishing},
edition = {1st},
abstract = {From the Publisher:Michael Sipser's philosophy in writing this book is simple: make the subject interesting and relevant, and the students will learn. His emphasis on unifying computer science theory - rather than offering a collection of low-level details - sets the book apart, as do his intuitive explanations. Throughout the book, Sipser - a noted authority on the theory of computation - builds students' knowledge of conceptual tools used in computer science, the aesthetic sense they need to create elegant systems, and the ability to think through problems on their own. INTRODUCTION TO THE THEORY OF COMPUTATION provides a mathematical treatment of computation theory grounded in theorems and proofs. Proofs are presented with a "proof idea" component to reveal the concepts underpinning the formalism. Algorithms are presented using prose instead of pseudocode to focus attention on the algorithms themselves, rather than on specific computational models. Topic coverage, terminology, and order of presentation are traditional for an upper-level course in computer science theory. Users of the Preliminary Edition (now out of print) will be interested to note several new chapters on complexity theory: Chapter 8 on space complexity; Chapter 9 on provable intractability, and Chapter 10 on advanced topics, including approximation algorithms, alternation, interactive proof systems, cryptography, and parallel computing.}
}

@book{10.5555/1196416,
author = {Hopcroft, John E. and Motwani, Rajeev and Ullman, Jeffrey D.},
title = {Introduction to Automata Theory, Languages, and Computation (3rd Edition)},
year = {2006},
isbn = {0321455363},
publisher = {Addison-Wesley Longman Publishing Co., Inc.},
address = {USA}
}

@article{schepper2018complexity,
  title={The Complexity of Formal Language Decision Problems},
  author={Schepper, Philipp Johann},
  year={2018}
}

@article{10.1145/3571252,
author = {Koutris, Paraschos and Deep, Shaleen},
title = {The Fine-Grained Complexity of CFL Reachability},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {POPL},
url = {https://doi.org/10.1145/3571252},
doi = {10.1145/3571252},
abstract = {Many problems in static program analysis can be modeled as the context-free language (CFL) reachability problem on directed labeled graphs. The CFL reachability problem can be generally solved in time O(n3), where n is the number of vertices in the graph, with some specific cases that can be solved faster. In this work, we ask the following question: given a specific CFL, what is the exact exponent in the monomial of the running time? In other words, for which cases do we have linear, quadratic or cubic algorithms, and are there problems with intermediate runtimes? This question is inspired by recent efforts to classify classic problems in terms of their exact polynomial complexity, known as fine-grained complexity. Although recent efforts have shown some conditional lower bounds (mostly for the class of combinatorial algorithms), a general picture of the fine-grained complexity landscape for CFL reachability is missing. Our main contribution is lower bound results that pinpoint the exact running time of several classes of CFLs or specific CFLs under widely believed lower bound conjectures (e.g., Boolean Matrix Multiplication, k-Clique, APSP, 3SUM). We particularly focus on the family of Dyck-k languages (which are strings with well-matched parentheses), a fundamental class of CFL reachability problems. Remarkably, we are able to show a Ω(n2.5) lower bound for Dyck-2 reachability, which to the best of our knowledge is the first super-quadratic lower bound that applies to all algorithms, and shows that CFL reachability is strictly harder that Boolean Matrix Multiplication. We also present new lower bounds for the case of sparse input graphs where the number of edges m is the input parameter, a common setting in the database literature. For this setting, we show a cubic lower bound for Andersen’s Pointer Analysis which significantly strengthens prior known results.},
journal = {Proc. ACM Program. Lang.},
month = {jan},
articleno = {59},
numpages = {27},
keywords = {fine-grained complexity, sparse graphs, Datalog, Dyck reachability, static pointer analysis}
}

@INPROCEEDINGS{6979046,
  author={Saha, Barna},
  booktitle={2014 IEEE 55th Annual Symposium on Foundations of Computer Science}, 
  title={The Dyck Language Edit Distance Problem in Near-Linear Time}, 
  year={2014},
  volume={},
  number={},
  pages={611-620},
  doi={10.1109/FOCS.2014.71}}

@article{ch-sch,
author = {Matthews, G.},
year = {2014},
month = {10},
pages = {388-389},
title = {Chomsky N. and Schützenberger M. P.. The algebraic theory of context-free languages. Computer programming and formal systems, edited by Braffort P. and Hirschberg D., Studies in logic and the foundations of mathematics, North-Holland Publishing Company, Amsterdam 1963, pp. 118–161.},
volume = {32},
journal = {The Journal of Symbolic Logic},
doi = {10.2307/2270782}
}

@inproceedings{williams2018some,
  title={On some fine-grained questions in algorithms and complexity},
  author={Williams, Virginia Vassilevska},
  booktitle={Proceedings of the international congress of mathematicians: Rio de janeiro 2018},
  pages={3447--3487},
  year={2018},
  organization={World Scientific}
}

@article{10.1006/jcss.2000.1727,
author = {Impagliazzo, Russell and Paturi, Ramamohan},
title = {On the Complexity of K-SAT},
year = {2001},
issue_date = {March 2001},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {62},
number = {2},
issn = {0022-0000},
url = {https://doi.org/10.1006/jcss.2000.1727},
doi = {10.1006/jcss.2000.1727},
abstract = {The k-SAT problem is to determine if a given k-CNF has a satisfying assignment. It is a celebrated open question as to whether it requires exponential time to solve k-SAT for k 3. Here exponential time means 2 n for some &gt;0. In this paper, assuming that, for k 3, k-SAT requires exponential time complexity, we show that the complexity of k-SAT increases as k increases. More precisely, for k 3, define sk=inf{ :there exists 2 n algorithm for solving k-SAT}. Define ETH (Exponential-Time Hypothesis) for k-SAT as follows: for k 3, sk&gt;0. In this paper, we show that sk is increasing infinitely often assuming ETH for k-SAT. Let s∞ be the limit of sk. We will in fact show that sk (1 d/k)s∞ for some constant d&gt;0. We prove this result by bringing together the ideas of critical clauses and the Sparsification Lemma to reduce the satisfiability of a k-CNF to the satisfiability of a disjunction of 2 nk -CNFs in fewer variables for some k k and arbitrarily small &gt;0. We also show that such a disjunction can be computed in time 2 n for arbitrarily small &gt;0.},
journal = {J. Comput. Syst. Sci.},
month = {mar},
pages = {367–375},
numpages = {9}
}

@inproceedings{10.5555/3458064.3458096,
author = {Alman, Josh and Williams, Virginia Vassilevska},
title = {A Refined Laser Method and Faster Matrix Multiplication},
year = {2021},
isbn = {9781611976465},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
abstract = {The complexity of matrix multiplication is measured in terms of ω, the smallest real number such that two n \texttimes{} n matrices can be multiplied using O(nω+ϵ) field operations for all ϵ &gt; 0; the best bound until now is ω &lt; 2.37287 [Le Gall'14]. All bounds on ω since 1986 have been obtained using the so-called laser method, a way to lower-bound the 'value' of a tensor in designing matrix multiplication algorithms. The main result of this paper is a refinement of the laser method that improves the resulting value bound for most sufficiently large tensors. Thus, even before computing any specific values, it is clear that we achieve an improved bound on ω, and we indeed obtain the best bound on ω to date:ω &lt; 2.37286.The improvement is of the same magnitude as the improvement that [Le Gall'14] obtained over the previous bound [Vassilevska W.'12]. Our improvement to the laser method is quite general, and we believe it will have further applications in arithmetic complexity.},
booktitle = {Proceedings of the Thirty-Second Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {522–539},
numpages = {18},
location = {Virtual Event, Virginia},
series = {SODA '21}
}

@article{10.1145/505241.505242,
author = {Lee, Lillian},
title = {Fast Context-Free Grammar Parsing Requires Fast Boolean Matrix Multiplication},
year = {2002},
issue_date = {January 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0004-5411},
url = {https://doi.org/10.1145/505241.505242},
doi = {10.1145/505241.505242},
abstract = {In 1975, Valiant showed that Boolean matrix multiplication can be used for parsing context-free grammars (CFGs), yielding the asympotically fastest (although not practical) CFG parsing algorithm known. We prove a dual result: any CFG parser with time complexity O(gn3-∈), where g is the size of the grammar and n is the length of the input string, can be efficiently converted into an algorithm to multiply m \texttimes{} m Boolean matrices in time O(m3-∈/3). Given that practical, substantially subcubic Boolean matrix multiplication algorithms have been quite difficult to find, we thus explain why there has been little progress in developing practical, substantially subcubic general CFG parsers. In proving this result, we also develop a formalization of the notion of parsing.},
journal = {J. ACM},
month = {jan},
pages = {1–15},
numpages = {15},
keywords = {Boolean matrix multiplication, context-free grammar parsing}
}

@inproceedings{10.1007/11786986_24,
author = {Vassilevska, Virginia and Williams, Ryan and Yuster, Raphael},
title = {Finding the Smallest H-Subgraph in Real Weighted Graphs and Related Problems},
year = {2006},
isbn = {3540359044},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11786986_24},
doi = {10.1007/11786986_24},
abstract = {Let G be a graph with real weights assigned to the vertices (edges). The weight of a subgraph of G is the sum of the weights of its vertices (edges). The MIN H-SUBGRAPH problem is to find a minimum weight subgraph isomorphic to H, if one exists. Our main results are new algorithms for the MIN H-SUBGRAPH problem. The only operations we allow on real numbers are additions and comparisons. Our algorithms are based, in part, on fast matrix multiplication.For vertex-weighted graphs with n vertices we obtain the following results. We present an O(nt(ω,h)) time algorithm for MIN H-SUBGRAPH in case H is a fixed graph with h vertices and ω&lt; 2.376 is the exponent of matrix multiplication. The value of t(ω,h) is determined by solving a small integer program. In particular, the smallest triangle can be found in O(n2+1/(4−ω)) ≤o(n2.616) time, the smallest K4 in O(nω+1) time, the smallest K7 in O(n4+3/(4−ω)) time. As h grows, t(ω,h) converges to 3h/(6-ω) &lt; 0.828h. Interestingly, only for h = 4,5,8 the running time of our algorithm essentially matches that of the (unweighted) H-subgraph detection problem. Already for triangles, our results improve upon the main result of [VW06]. Using rectangular matrix multiplication, the value of t(ω,h) can be improved; for example, the runtime for triangles becomes O(n2.575). We also present an algorithm whose running time is a function of m, the number of edges. In particular, the smallest triangle can be found in O(m(18−4ω)/(13−3ω)) ≤o(m1.45) time.For edge-weighted graphs we present an O(m2−1/k logn) time algorithm that finds the smallest cycle of length 2k or 2k-1. This running time is identical, up to a logarithmic factor, to the running time of the algorithm of Alon et al. for the unweighted case. Using the color coding method and a recent algorithm of Chan for distance products, we obtain an O(n3/logn) time randomized algorithm for finding the smallest cycle of any fixed length.},
booktitle = {Proceedings of the 33rd International Conference on Automata, Languages and Programming - Volume Part I},
pages = {262–273},
numpages = {12},
location = {Venice, Italy},
series = {ICALP'06}
}

@article{10.1145/1798596.1798597,
author = {Vassilevska, Virginia and Williams, Ryan and Yuster, Raphael},
title = {Finding Heaviest H-Subgraphs in Real Weighted Graphs, with Applications},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
issn = {1549-6325},
url = {https://doi.org/10.1145/1798596.1798597},
doi = {10.1145/1798596.1798597},
abstract = {For a graph G with real weights assigned to the vertices (edges), the MAX H-SUBGRAPH problem is to find an H-subgraph of G with maximum total weight, if one exists. Our main results are new strongly polynomial algorithms for the MAX H-SUBGRAPH problem. Some of our algorithms are based, in part, on fast matrix multiplication.For vertex-weighted graphs with n vertices we solve a more general problem: the all pairs MAX H-SUBGRAPH problem, where the task is to find for every pair of vertices u,v, a maximum H-subgraph containing both u and v, if one exists. We obtain an O(nt(ω,h))-time algorithm for the all pairs MAX H-SUBGRAPH problem in the case where H is a fixed graph with h vertices and ω &lt; 2.376 is the exponent of matrix multiplication. The value of t(ω,h) is determined by solving a small integer program. In particular, heaviest triangles for all pairs can be found in O(n2+1/(4-ω)) ≤ o(n2.616)-time. For h=4,5,8 the running time of our algorithm essentially matches that of the (unweighted) H-subgraph detection problem. Using rectangular matrix multiplication, the value of t(ω,h) can be improved; for example, the runtime for triangles becomes O(n2.575).We also present improved algorithms for the MAX H-SUBGRAPH problem in the edge-weighted case. In particular, we obtain an O(m2−1/k log n)-time algorithm for the heaviest cycle of length 2k or 2k−1 in a graph with m edges and an O(n3/log n)-time randomized algorithm for finding the heaviest cycle of any fixed length.Our methods also yield efficient algorithms for several related problems that are faster than any previously existing algorithms. For example, we show how to find chromatic H-subgraphs in edge-colored graphs, and how to compute the most significant bits of the distance product of two real matrices, in truly subcubic time.},
journal = {ACM Trans. Algorithms},
month = {jul},
articleno = {44},
numpages = {23},
keywords = {H-subgraph, matrix multiplication, weighted graph}
}

@article{https://doi.org/10.4230/lipics.itcs.2020.53,
doi = {10.4230/LIPICS.ITCS.2020.53},
url = {https://drops.dagstuhl.de/opus/volltexte/2020/11738/},
author = {Lincoln, Andrea and Polak, Adam and Vassilevska Williams, Virginia},
keywords = {Computer Science, 000 Computer science, knowledge, general works},
language = {en},
title = {Monochromatic Triangles, Intermediate Matrix Products, and Convolutions},
publisher = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik GmbH, Wadern/Saarbruecken, Germany},
year = {2020},
copyright = {Creative Commons Attribution 3.0 Unported license (CC-BY 3.0)}
}

@inproceedings{10.1145/2746539.2746594,
author = {Abboud, Amir and Vassilevska Williams, Virginia and Yu, Huacheng},
title = {Matching Triangles and Basing Hardness on an Extremely Popular Conjecture},
year = {2015},
isbn = {9781450335362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2746539.2746594},
doi = {10.1145/2746539.2746594},
abstract = {Due to the lack of unconditional polynomial lower bounds, it is now in fashion to prove conditional lower bounds in order to advance our understanding of the class P. The vast majority of these lower bounds are based on one of three famous hypotheses: the 3-SUM conjecture, the APSP conjecture, and the Strong Exponential Time Hypothesis. Only circumstantial evidence is known in support of these hypotheses, and no formal relationship between them is known. In hopes of obtaining "less conditional" and therefore more reliable lower bounds, we consider the conjecture that at least one of the above three hypotheses is true. We design novel reductions from 3-SUM, APSP, and CNF-SAT, and derive interesting consequences of this very plausible conjecture, including: Tight n3-o(1) lower bounds for purely-combinatorial problems about the triangles in unweighted graphs. New n1-o(1) lower bounds for the amortized update and query times of dynamic algorithms for single-source reachability, strongly connected components, and Max-Flow. New n1.5-o(1) lower bound for computing a set of n st-maximum-flow values in a directed graph with n nodes and ~O(n) edges. There is a hierarchy of natural graph problems on n nodes with complexity nc for c ∈ (2,3).Only slightly non-trivial consequences of this conjecture were known prior to our work. Along the way we also obtain new conditional lower bounds for the Single-Source-Max-Flow problem.},
booktitle = {Proceedings of the Forty-Seventh Annual ACM Symposium on Theory of Computing},
pages = {41–50},
numpages = {10},
keywords = {3sum, CNF-SAT, APSP, conditional lower bounds, dynamic data structures, seth, reductions, single-source max-flow},
location = {Portland, Oregon, USA},
series = {STOC '15}
}

@article{10.1016/j.tcs.2005.09.023,
author = {Williams, Ryan},
title = {A New Algorithm for Optimal 2-Constraint Satisfaction and Its Implications},
year = {2005},
issue_date = {8 December 2005},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {348},
number = {2},
issn = {0304-3975},
url = {https://doi.org/10.1016/j.tcs.2005.09.023},
doi = {10.1016/j.tcs.2005.09.023},
abstract = {We present a novel method for exactly solving (in fact, counting solutions to) general constraint satisfaction optimization with at most two variables per constraint (e.g. MAX-2-CSP and MIN-2-CSP), which gives the first exponential improvement over the trivial algorithm. More precisely, the runtime bound is a constant factor improvement in the base of the exponent: the algorithm can count the number of optima in MAX-2-SAT and MAX-CUT instances in O(m32ωn/3) time, where ω &lt; 2.376 is the matrix product exponent over a ring. When the constraints have arbitrary weights, there is a (1 + ε)-approximation with roughly the same runtime, modulo polynomial factors. Our construction shows that improvement in the runtime exponent of either k-clique solution (even when k = 3) or matrix multiplication over GF(2) would improve the runtime exponent for solving 2-CSP optimization.Our approach also yields connections between the complexity of some (polynomial time) high-dimensional search problems and some NP-hard problems. For example, if there are sufficiently faster algorithms for computing the diameter of n points in l1, then there is an (2 - ε)n algorithm for MAX-LIN. These results may be construed as either lower bounds on the high-dimensional problems, or hope that better algorithms exist for the corresponding hard problems.},
journal = {Theor. Comput. Sci.},
month = {dec},
pages = {357–365},
numpages = {9},
keywords = {constraint satisfaction, exact algorithms, MAX-2-SAT, MAX-CUT}
}


@article{CHOMSKY1959137,
title = {On certain formal properties of grammars},
journal = {Information and Control},
volume = {2},
number = {2},
pages = {137-167},
year = {1959},
issn = {0019-9958},
doi = {https://doi.org/10.1016/S0019-9958(59)90362-6},
url = {https://www.sciencedirect.com/science/article/pii/S0019995859903626},
author = {Noam Chomsky},
abstract = {A grammar can be regarded as a device that enumerates the sentences of a language. We study a sequence of restrictions that limit grammars first to Turing machines, then to two types of system from which a phrase structure description of the generated language can be drawn, and finally to finite state Markov sources (finite automata). These restrictions are shown to be increasingly heavy in the sense that the languages that can be generated by grammars meeting a given restriction constitute a proper subset of those that can be generated by grammars meeting the preceding restriction. Various formulations of phrase structure description are considered, and the source of their excess generative power over finite state sources is investigated in greater detail.}
}

@inproceedings{Williams2009TriangleDV,
  title={Triangle Detection Versus Matrix Multiplication : A Study of Truly Subcubic Reducibility ∗},
  author={Virginia Vassilevska Williams and Ryan Williams},
  year={2009}
}

@article{10.1137/0201022,
author = {Aho, Alfred V. and Peterson, Thomas G.},
title = {A Minimum Distance Error-Correcting Parser for Context-Free Languages},
year = {1972},
issue_date = {Dec 1972},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {1},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0201022},
doi = {10.1137/0201022},
abstract = {We assume three types of syntax errors can debase the sentences of a language generated by a context-free grammar: the replacement of a symbol by an incorrect symbol, the insertion of an extraneous symbol, or the deletion of a symbol. We present an algorithm that will parse any input string to completion finding the fewest possible number of errors. On a random access computer the algorithm requires time proportional to the cube of the length of the input.},
journal = {SIAM J. Comput.},
month = {dec},
pages = {305–312},
numpages = {8},
keywords = {computational complexity, Syntax error, error correction, parsing, context-free grammar}
}

@article{10.1137/0201022,
author = {Aho, Alfred V. and Peterson, Thomas G.},
title = {A Minimum Distance Error-Correcting Parser for Context-Free Languages},
year = {1972},
issue_date = {Dec 1972},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {1},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0201022},
doi = {10.1137/0201022},
abstract = {We assume three types of syntax errors can debase the sentences of a language generated by a context-free grammar: the replacement of a symbol by an incorrect symbol, the insertion of an extraneous symbol, or the deletion of a symbol. We present an algorithm that will parse any input string to completion finding the fewest possible number of errors. On a random access computer the algorithm requires time proportional to the cube of the length of the input.},
journal = {SIAM J. Comput.},
month = {dec},
pages = {305–312},
numpages = {8},
keywords = {error correction, parsing, context-free grammar, computational complexity, Syntax error}
}

@article{10.1016/0020-0190(95)00007-Y,
author = {Myers, Gene},
title = {Approximately Matching Context-Free Languages},
year = {1995},
issue_date = {April 28, 1995},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {54},
number = {2},
issn = {0020-0190},
url = {https://doi.org/10.1016/0020-0190(95)00007-Y},
doi = {10.1016/0020-0190(95)00007-Y},
journal = {Inf. Process. Lett.},
month = {apr},
pages = {85–92},
numpages = {8},
keywords = {design of algorithms, sequence comparison, pattern matching}
}

@article{DBLP:journals/corr/Saha14,
  author       = {Barna Saha},
  title        = {Faster Language Edit Distance, Connection to All-pairs Shortest Paths
                  and Related Problems},
  journal      = {CoRR},
  volume       = {abs/1411.7315},
  year         = {2014},
  url          = {http://arxiv.org/abs/1411.7315},
  eprinttype    = {arXiv},
  eprint       = {1411.7315},
  timestamp    = {Mon, 13 Aug 2018 16:46:45 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/Saha14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/BringmannGSW17,
  author       = {Karl Bringmann and
                  Fabrizio Grandoni and
                  Barna Saha and
                  Virginia Vassilevska Williams},
  title        = {Truly Sub-cubic Algorithms for Language Edit Distance and {RNA} Folding
                  via Fast Bounded-Difference Min-Plus Product},
  journal      = {CoRR},
  volume       = {abs/1707.05095},
  year         = {2017},
  url          = {http://arxiv.org/abs/1707.05095},
  eprinttype    = {arXiv},
  eprint       = {1707.05095},
  timestamp    = {Mon, 13 Aug 2018 16:47:29 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/BringmannGSW17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{PIERRE1992279,
title = {Rational indexes of generators of the cone of context-free languages},
journal = {Theoretical Computer Science},
volume = {95},
number = {2},
pages = {279-305},
year = {1992},
issn = {0304-3975},
doi = {https://doi.org/10.1016/0304-3975(92)90269-L},
url = {https://www.sciencedirect.com/science/article/pii/030439759290269L},
author = {Laurent Pierre},
abstract = {The rational index ϱL of a non-empty language L is a non-decreasing function fromN∗ into N, whose asymptotic behavior can be used to classify languages. The rational index behaves well when combined with rational transductions: if a language L rationally dominates another language L′ (i.e. there exists a rational transduction τ, such that τ(L)=L′, then ϱL the rational index of L, provides an upper bound on ϱL′, since ∃c∈N∗,∀n∈N∗,cn(ϱL(cn)+1)⩾ϱL′(n). Hence all the generators of the rational cone of context-free languages, i.e. the context-free languages which dominate any context-free language, have roughly the same rational indexes, which were known to belong to exp Ω(n)∩exp O(n2). This paper improves these bounds. Indeed the rational index of any generator of the rational cone of context-free languages belongs to exp Θ(n2/lnn).}
}

@article{10.1006/jcss.1997.1388,
author = {Alon, Noga and Galil, Zvi and Margalit, Oded},
title = {On the Exponent of the All Pairs Shortest Path Problem},
year = {1997},
issue_date = {April 1997},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {54},
number = {2},
issn = {0022-0000},
url = {https://doi.org/10.1006/jcss.1997.1388},
doi = {10.1006/jcss.1997.1388},
abstract = {The upper bound on the exponent, , of matrix multiplication over a ring that was three in 1968 has decreased several times and since 1986 it has been 2.376. On the other hand, the exponent of the algorithms known for the all pairs shortest path problem has stayed at three all these years even for the very special case of directed graphs with uniform edge lengths. In this paper we give an algorithm of timeO(n log3n), =(3+ )/2, for the case of edge lengths in { 1, 0, 1}. Thus, for the current known bound on , we get a bound on the exponent, &lt;2.688. In case of integer edge lengths with absolute value bounded above byM, the time bound isO((Mn) log3n) and the exponent is less than 3 forM=O(n ), for &lt;0.116 and the current bound on .},
journal = {J. Comput. Syst. Sci.},
month = {apr},
pages = {255–262},
numpages = {8}
}

@article{lspidwnapew,
author = {Bradford, Phillip and Thomas, David},
year = {2009},
month = {07},
pages = {},
title = {Labeled shortest paths in digraphs with negative and positive edge weights},
volume = {43},
journal = {http://dx.doi.org/10.1051/ita/2009011},
doi = {10.1051/ita/2009011}
}

@inproceedings{Rytter2005FastRO,
  title={Fast Recognition of Pushdown Automaton Context-free Languages},
  author={Wojciech Rytter},
  year={2005}
}

@article{10.1145/3498702,
author = {Chistikov, Dmitry and Majumdar, Rupak and Schepper, Philipp},
title = {Subcubic Certificates for CFL Reachability},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {POPL},
url = {https://doi.org/10.1145/3498702},
doi = {10.1145/3498702},
abstract = {Many problems in interprocedural program analysis can be modeled as the context-free language (CFL) reachability problem on graphs and can be solved in cubic time. Despite years of efforts, there are no known truly sub-cubic algorithms for this problem. We study the related certification task: given an instance of CFL reachability, are there small and efficiently checkable certificates for the existence and for the non-existence of a path? We show that, in both scenarios, there exist succinct certificates (O(n2) in the size of the problem) and these certificates can be checked in subcubic (matrix multiplication) time. The certificates are based on grammar-based compression of paths (for reachability) and on invariants represented as matrix inequalities (for non-reachability). Thus, CFL reachability lies in nondeterministic and co-nondeterministic subcubic time. A natural question is whether faster algorithms for CFL reachability will lead to faster algorithms for combinatorial problems such as Boolean satisfiability (SAT). As a consequence of our certification results, we show that there cannot be a fine-grained reduction from SAT to CFL reachability for a conditional lower bound stronger than nω, unless the nondeterministic strong exponential time hypothesis (NSETH) fails. In a nutshell, reductions from SAT are unlikely to explain the cubic bottleneck for CFL reachability. Our results extend to related subcubic equivalent problems: pushdown reachability and 2NPDA recognition; as well as to all-pairs CFL reachability. For example, we describe succinct certificates for pushdown non-reachability (inductive invariants) and observe that they can be checked in matrix multiplication time. We also extract a new hardest 2NPDA language, capturing the “hard core” of all these problems.},
journal = {Proc. ACM Program. Lang.},
month = {jan},
articleno = {41},
numpages = {29},
keywords = {CFL reachability, subcubic certification, pushdown reachability}
}