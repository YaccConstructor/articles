\section{Conclusion}

In this work we evaluated Spla---linear-algebra-based graph analysis library---on RISC-V IAS based GPGPU Vortex.
We show that Spla is portable enough to be run on Vortex. Vortex ready to run. Scaling. !!!!! 

Several directions remain for future work.
First, it is necessary to resolve issues with floating-point operations and to conduct experiments with additional algorithms such as PageRank and single-source shortest path (SSSP).
Furthermore, evaluating Spla on Vortex across a broader set of diverse graphs would yield more robust scaling insights.

After simulation-based evaluation in SimX, the next step is to estimate the FPGA resources required for the most performant configuration and to perform actual evaluations on different FPGA platforms, when atomics support will be finished.

Another promising direction is analyzing the applicability of SparseWeaver to sparse-linear-algebra-based graph analysis.
Prior work has shown that SparseWeaver improves the performance of manually crafted graph algorithms and has suggested its potential for optimizing sparse linear algebra kernels~\cite{10946718}.

We also plan to evaluate Spla on Ventus~\footnote{Ventus GPU project page: \url{https://github.com/THU-DSP-LAB/ventus-gpgpu}}~\cite{VentusICCD2024}, another RISC-V-based GPGPU, and to compare its performance with Vortex.

Applicability of open-source GPUs such as Vortex or Ventus as a foundation for specialized processors dedicated to sparse-linear-algebra-based graph analysis is a goal for future research.

