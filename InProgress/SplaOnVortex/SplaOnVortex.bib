@inproceedings{10.1145/3466752.3480128,
author = {Tine, Blaise and Yalamarthy, Krishna Praveen and Elsabbagh, Fares and Hyesoon, Kim},
title = {Vortex: Extending the RISC-V ISA for GPGPU and 3D-Graphics},
year = {2021},
isbn = {9781450385572},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3466752.3480128},
doi = {10.1145/3466752.3480128},
abstract = {The importance of open-source hardware and software has been increasing. However, despite GPUs being one of the more popular accelerators across various applications, there is very little open-source GPU infrastructure in the public domain. We argue that one of the reasons for the lack of open-source infrastructure for GPUs is rooted in the complexity of their ISA and software stacks. In this work, we first propose an ISA extension to RISC-V that supports GPGPUs and graphics. The main goal of the ISA extension proposal is to minimize the ISA changes so that the corresponding changes to the open-source ecosystem are also minimal, which makes for a sustainable development ecosystem. To demonstrate the feasibility of the minimally extended RISC-V ISA, we implemented the complete software and hardware stacks of Vortex on FPGA. Vortex is a PCIe-based soft GPU that supports OpenCL and OpenGL. Vortex can be used in a variety of applications, including machine learning, graph analytics, and graphics rendering. Vortex can scale up to 32 cores on an Altera Stratix 10 FPGA, delivering a peak performance of 25.6 GFlops at 200 Mhz.},
booktitle = {MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {754–766},
numpages = {13},
keywords = {computer graphics, memory systems., reconfigurable computing},
location = {Virtual Event, Greece},
series = {MICRO '21}
}

@INPROCEEDINGS{9460572,
  author={Brock, Benjamin and Buluç, Aydın and Mattson, Timothy G. and McMillan, Scott and Moreira, José E.},
  booktitle={2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Introduction to GraphBLAS 2.0}, 
  year={2021},
  volume={},
  number={},
  pages={253-262},
  keywords={Computer languages;Distributed processing;Multithreading;Conferences;Collaboration;Linear algebra;Software},
  doi={10.1109/IPDPSW52791.2021.00047}}

@article{10.1145/3466795,
author = {Yang, Carl and Bulu\c{c}, Ayd\i{}n and Owens, John D.},
title = {GraphBLAST: A High-Performance Linear Algebra-based Graph Framework on the GPU},
year = {2022},
issue_date = {March 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0098-3500},
url = {https://doi.org/10.1145/3466795},
doi = {10.1145/3466795},
abstract = {High-performance implementations of graph algorithms are challenging to implement on new parallel hardware such as GPUs because of three challenges: (1)&nbsp;the difficulty of coming up with graph building blocks, (2)&nbsp;load imbalance on parallel hardware, and (3)&nbsp;graph problems having low arithmetic intensity. To address some of these challenges, GraphBLAS is an innovative, on-going effort by the graph analytics community to propose building blocks based on sparse linear algebra, which allow graph algorithms to be expressed in a performant, succinct, composable, and portable manner. In this paper, we examine the performance challenges of a linear-algebra-based approach to building graph frameworks and describe new design principles for overcoming these bottlenecks. Among the new design principles is exploiting input sparsity, which allows users to write graph algorithms without specifying push and pull direction. Exploiting output sparsity allows users to tell the backend which values of the output in a single vectorized computation they do not want computed. Load-balancing is an important feature for balancing work amongst parallel workers. We describe the important load-balancing features for handling graphs with different characteristics. The design principles described in this paper have been implemented in “GraphBLAST”, the first high-performance linear algebra-based graph framework on NVIDIA GPUs that is open-source. The results show that on a single GPU, GraphBLAST has on average at least an order of magnitude speedup over previous GraphBLAS implementations SuiteSparse and GBTL, comparable performance to the fastest GPU hardwired primitives and shared-memory graph frameworks Ligra and Gunrock, and better performance than any other GPU graph framework, while offering a simpler and more concise programming model.},
journal = {ACM Trans. Math. Softw.},
month = feb,
articleno = {1},
numpages = {51},
keywords = {Graph algorithm, GPU, sparse linear algebra, matrix multiply}
}  

@article{10.1145/3577195,
author = {Davis, Timothy A.},
title = {Algorithm~1037: SuiteSparse:GraphBLAS: Parallel Graph Algorithms in the Language of Sparse Linear Algebra},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {3},
issn = {0098-3500},
url = {https://doi.org/10.1145/3577195},
doi = {10.1145/3577195},
abstract = {SuiteSparse:GraphBLAS is a full parallel implementation of the GraphBLAS standard, which defines a set of sparse matrix operations on an extended algebra of semirings using an almost unlimited variety of operators and types. When applied to sparse adjacency matrices, these algebraic operations are equivalent to computations on graphs. A description of the parallel implementation of SuiteSparse:GraphBLAS is given, including its novel parallel algorithms for sparse matrix multiply, addition, element-wise multiply, submatrix extraction and assignment, and the GraphBLAS mask/accumulator operation. Its performance is illustrated by solving the graph problems in the GAP Benchmark and by comparing it with other sparse matrix libraries.},
journal = {ACM Trans. Math. Softw.},
month = sep,
articleno = {28},
numpages = {30},
keywords = {Graph algorithms, sparse matrices, GraphBLAS}
}

@INPROCEEDINGS{VentusICCD2024,
  author={Li, Jingzhou and Yang, Kexiang and Jin, Chufeng and Liu, Xudong and Yang, Zexia and Yu, Fangfei and Shi, Yujie and Ma, Mingyuan and Kong, Li and Zhou, Jing and Wu, Hualin and He, Hu},
  booktitle={2024 IEEE 42nd International Conference on Computer Design (ICCD)}, 
  title={Ventus: A High-performance Open-source GPGPU Based on RISC-V and Its Vector Extension}, 
  year={2024},
  pages={276-279},
  keywords={Generative AI;Large language models;Graphics processing units;Full stack;Computer architecture;Vectors;Software;Open source hardware;Field programmable gate arrays;Software development management;GPGPU;Open-source Design;RISC-V;Vector},
  doi={10.1109/ICCD63220.2024.00049}}

@article{10.1007/s10766-014-0320-y,
author = {J\"{a}\"{a}skel\"{a}inen, Pekka and Lama, Carlos S\'{a}nchez and Schnetter, Erik and Raiskila, Kalle and Takala, Jarmo and Berg, Heikki},
title = {pocl: A Performance-Portable OpenCL Implementation},
year = {2015},
issue_date = {October   2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {43},
number = {5},
issn = {0885-7458},
url = {https://doi.org/10.1007/s10766-014-0320-y},
doi = {10.1007/s10766-014-0320-y},
abstract = {OpenCL is a standard for parallel programming of heterogeneous systems. The benefits of a common programming standard are clear; multiple vendors can provide support for application descriptions written according to the standard, thus reducing the program porting effort. While the standard brings the obvious benefits of platform portability, the performance portability aspects are largely left to the programmer. The situation is made worse due to multiple proprietary vendor implementations with different characteristics, and, thus, required optimization strategies. In this paper, we propose an OpenCL implementation that is both portable and performance portable. At its core is a kernel compiler that can be used to exploit the data parallelism of OpenCL programs on multiple platforms with different parallel hardware styles. The kernel compiler is modularized to perform target-independent parallel region formation separately from the target-specific parallel mapping of the regions to enable support for various styles of fine-grained parallel resources such as subword SIMD extensions, SIMD datapaths and static multi-issue. Unlike previous similar techniques that work on the source level, the parallel region formation retains the information of the data parallelism using the LLVM IR and its metadata infrastructure. This data can be exploited by the later generic compiler passes for efficient parallelization. The proposed open source implementation of OpenCL is also platform portable, enabling OpenCL on a wide range of architectures, both already commercialized and on those that are still under research. The paper describes how the portability of the implementation is achieved. We test the two aspects to portability by utilizing the kernel compiler and the OpenCL implementation to run OpenCL applications in various platforms with different style of parallel resources. The results show that most of the benchmarked applications when compiled using pocl were faster or close to as fast as the best proprietary OpenCL implementation for the platform at hand.},
journal = {Int. J. Parallel Program.},
month = oct,
pages = {752–785},
numpages = {34},
keywords = {VLIW, SIMD, Performance portability, Parallel programming, OpenCL, LLVM, Heterogeneous platforms, GPGPU}
}

@mastersthesis{spla,
  author  = {Orachev, Egor},
  title   = {Generalized sparse linear algebra library with vendor-agnostic GPUs acceleration},
  school  = {Saint Petersburg State University},
  year    = {2023}
}

@inproceedings{shah2022graph,
  title={Graph Analytics on RISC-V GPU: Where are the Bottlenecks?},
  author={Shah, Nimish and Verhelst, Marian},
  booktitle={Spring 2022 RISC-V Week, Location: Paris, France},
  year={2022}
}

@ARTICLE{Ravikumar2025-cc,
  title     = "Parallel graph algorithms on a {RISCV-based} many-core",
  author    = "Ravikumar, Ashuthosh Moolemajalu and Vinay, Aakarsh and Nagar,
               Krishna K and Purnaprajna, Madhura",
  abstract  = "Graph algorithms are essential in domains like social network
               analysis, web search, and bioinformatics. Their execution on
               modern hardware is vital due to the growing size and complexity
               of graphs. Traditional multi-core systems struggle with
               irregular memory access patterns in graph workloads. Reduced
               instruction set computer--five (RISC-V)-based many-core
               processors offer a promising alternative with their customizable
               open-source architecture suitable for optimization. This work
               focuses on parallelizing graph algorithms like breadth-first
               search (BFS) and PageRank (PR) on RISC-V many-core systems. We
               evaluated performance based on graph structure and processor
               architecture, and developed an analytical model to predict
               execution time. The model incorporates the unique
               characteristics of the RISC-V architecture and the types and
               numbers of instructions executed by multiple cores, with a
               maximum prediction error of 11\%. Our experiments show a speedup
               of up to 11.55$\times$ for BFS and 7.56$\times$ for PR using 16
               and 8 cores, respectively, over single-core performance.
               Comparisons with existing graph processing frameworks
               demonstrate that RISC-V systems can deliver up to 20$\times$
               better energy efficiency on real-world graphs from the network
               repository.",
  journal   = "Int. J. Reconfigurable Embed. Syst. (IJRES)",
  publisher = "Institute of Advanced Engineering and Science",
  volume    =  14,
  number    =  3,
  pages     = "843",
  month     =  nov,
  year      =  2025
}

@inproceedings{10.1145/3641584.3641670,
author = {Zhou, Kai and Deng, Junyong and Zeng, Yukai},
title = {Design and Memory Access Optimization of Graph processing Processor design Based on RISC-V},
year = {2024},
isbn = {9798400707674},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641584.3641670},
doi = {10.1145/3641584.3641670},
abstract = {In the context of big data, many applications are represented by graph structure, and graph processing has become the research focus of the data-driven market. As an important platform for processing graph processing tasks, general-purpose processors have strong scalability and can reduce the running time of computing tasks through complex logic structures, but they also face the challenge of irregular memory access. Therefore, it is important to improve the challenge of irregular memory access on general processor hardware platforms and the execution efficiency of graph processing. The emerging open-source instruction set architecture of RISC-V has the advantage of being customizable. This article proposes a preprocessing method for node address prediction to address the issue of irregular memory access in graph processing. Based on dedicated graph processing extension instructions, a RISC-V graph processing processor architecture is designed to achieve fast processing of graph processing tasks. In this paper, Verilog HDL is used to complete the circuit design of the graph processing processor, and a prototype system is developed based on the Xilinx Alveo U280. The performance of the graph processing processor is verified on SNAP and NR data sets by the breadth-first search algorithm, degree centrality algorithm, and connected component algorithm. The results show that compared with the mainstream graph processing accelerator ReGraph, the resource used is reduced by 59.4\%, the total power consumption is reduced by 88\%, and the energy efficiency ratio is increased by 9.26\texttimes{}.},
booktitle = {Proceedings of the 2023 6th International Conference on Artificial Intelligence and Pattern Recognition},
pages = {576–583},
numpages = {8},
keywords = {Breadth-First Search, Connected Components, Custom Extensions Instructions, Degree Centrality, RISC-V},
location = {Xiamen, China},
series = {AIPR '23}
}


@inproceedings{guthmuller:cea-05043041,
  TITLE = {{GPGPUs on FPGAs: A competitive approach for scientific computing ?}},
  AUTHOR = {Guthmuller, Eric and Fereyre, J{\'e}rome and Herrera-Marti, David},
  URL = {https://cea.hal.science/cea-05043041},
  BOOKTITLE = {{DATE 2025 - Design, Automation and Test in Europe Conference}},
  ADDRESS = {Lyon, France},
  YEAR = {2025},
  MONTH = Mar,
  KEYWORDS = {scientific computing ; floating point ; FPGA ; GPGPU},
  PDF = {https://cea.hal.science/cea-05043041v1/file/DATE_OSSMPIC_2025_202503251516.pdf},
  HAL_ID = {cea-05043041},
  HAL_VERSION = {v1},
}

@INPROCEEDINGS{10946718,
  author={Jeong, Shinnung and Cooper, Liam Paul and Lee, Ju Min and Choi, Heelim and Parnenzini, Nicholas and Ahn, Chihyo and Lee, Yongwoo and Kim, Hanjun and Kim, Hyesoon},
  booktitle={2025 IEEE International Symposium on High Performance Computer Architecture (HPCA)}, 
  title={SparseWeaver: Converting Sparse Operations as Dense Operations on GPUs for Graph Workloads}, 
  year={2025},
  volume={},
  number={},
  pages={1437-1451},
  keywords={Instruction sets;Graphics processing units;Collaboration;Prototypes;Software;Hardware;Registers;Topology;Logic;Synchronization;graph processing;sparsity;gpu;microarchitecture},
  doi={10.1109/HPCA61900.2025.00108}}

  @THESIS{Yenimol.2022,
    author = {Yenimol, Mehmetali Semi},
    advisor = {Öztürk, Özcan},
    title = {Hardware/software Co-design of domain-specific RISC-V processor for graph applications},
    altTitle = {Çizge uygulamaları için alana özgü RISC-V işlemcisinin donanım/yazılım ortak tasarımı},
    year = {2022},
    submitted = {2022-05-27},
    language = {English},
    institution = {Bilkent University},
    degree = {MS (Master of Science)},
    discipline = {Computer Engineering},
    abstract = {Graph applications are employed in many fields but show poor performance on general-purpose computing systems due to heavy, irregular, and data-driven memory access patterns. The diverse topology of real-life graphs also affects the performance. Even though many hardware accelerators have been proposed to mitigate performance issues and provide energy efficiency, programmability and flexibility have not been sufficiently addressed. This thesis presents a domain-specific processor design based on extending the RISC-V Instruction Set Architecture (ISA). The proposed approach uses new instructions supported by the compiler and software library. Micro-architectural design for executing the new instructions is based on a scratchpad-memory (SPM), prefetcher, and a non-blocking cache system. The custom processor is implemented using System Verilog HDL and simulated with Xilinx's Vivado Design Suite. LLVM Compiler Framework is used for compiler support and optimization. The software library for utilizing the custom instructions uses Gather-Apply-Scatter (GAS) paradigm. The system is evaluated on well-known graph benchmarks, while sensitivity analysis is done on various parameters for achieving the best performance with minimal cost. Performance is measured on both native benchmarks and the software library. In addition, compiler support is evaluated for its effect on performance. Cost-efficient performance evaluations show average speedups between 10% and 49% for different benchmarks, while the single-core architecture can achieve up to 73%.},
    keywords = {Domain-specific processor, Graph applications, RISC-V, Hardware/-software Co-design},
    url = {http://hdl.handle.net/11693/80659}
  }

@INPROCEEDINGS{10596403,
  author={Vizcaino, Pablo and Labarta, Jesus and Mantovani, Filippo},
  booktitle={2024 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Graph Computing on Long Vector Architectures (Yes, It Works!)}, 
  year={2024},
  volume={},
  number={},
  pages={986-995},
  keywords={Sockets;Platinum;Prototypes;Computer architecture;Bandwidth;Vectors;Libraries;Graphs;Vector;RISC-V;SX-Aurora;optimization;BFS;PR;CC},
  doi={10.1109/IPDPSW63119.2024.00169}}
