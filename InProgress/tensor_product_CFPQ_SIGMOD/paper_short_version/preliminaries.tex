\section{Preliminaries}

In this section we introduce basic notation and definitions from graph theory and formal language theory.

\subsection{Language-Constrained Path Querying Problem}

We use a directed edge-labeled graph as a data model.
To introduce the \term{Language-Constraint Path Querying Problem}~\cite{barrett2000formal} over directed edge-labeled graphs we first give both language and grammar definitions.

\begin{definition}
An \term{edge-labeled directed graph} $\mathcal{G}$ is a triple $\langle V,E,L \rangle$, where $V = \{0, \ldots, |V|-1\}$ is a finite set of vertices, $E \subseteq V \times L \times V$ is a finite set of edges and $L$ is a finite set of edge labels.
\end{definition}

The example of a graph which we use in the further examples is presented in Figure~\ref{fig:example_input_graph}.

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[
        shorten >=1pt,
        auto]

        \node[state] (q_2)                              {$2$};
        \node[state] (q_0) [left=of q_2, yshift=-0.7cm] {$0$};
        \node[state] (q_1) [left=of q_2, yshift=0.7cm]  {$1$};
        \node[state] (q_3) [right=of q_2]               {$3$};
        \path[->]
        (q_0) edge node {a} (q_1)
        (q_1) edge node {a} (q_2)
        (q_2) edge node {a} (q_0)
        (q_2) edge[bend left, above]  node {b} (q_3)
        (q_3) edge[bend left, below]  node {b} (q_2);
    \end{tikzpicture}
    \caption{The example of input graph $\mathcal{G}$}
    \label{fig:example_input_graph}
\end{figure}

\begin{definition}
An \term{adjacency matrix} for an edge-labeled directed graph $\mathcal{G} = \langle V,E,L \rangle$ is a matrix $M$, which has size $|V|\times|V|$ and $M[i,j] = \{l~\mid e = (i,l,j) \in E\}$.
\end{definition}

Adjacency matrix $M_2$ of the graph $\mathcal{G}$ is
$$
    M_2 =
    \begin{pmatrix}
    . & \{a\} & . & .     \\
    . & . & \{a\} & .     \\
    \{a\} & . & . & \{b\} \\
    . & . & \{b\} & .
    \end{pmatrix}.
$$

\begin{definition}
The \term{Boolean matrices decomposition}, or \term{Boolean adjacency matrix},
for an edge-labeled directed graph $\mathcal{G} =
\langle V,E,L \rangle$ with adjacency matrix $M$ is a set of matrices $\mathcal{M} = \{ M^l~\mid~l \in L,M^l[i,j] = 1 \iff l \in M[i,j]\}$.
\end{definition}

We use the decomposition of the adjacency matrix into a set of Boolean matrices. As an example, matrix $M_2$ can be represented as a set of two Boolean matrices $M_2^a$ and $M_2^b$:
\begin{align*}
M_2^{a} =
\begin{pmatrix}
    . & 1 & . & .   \\
    . & . & 1 & .   \\
    1 & . & . & .   \\
    . & . & . & .
\end{pmatrix},
M_2^{b} =
\begin{pmatrix}
    . & . & . & .   \\
    . & . & . & .   \\
    . & . & . & 1   \\
    . & . & 1 & .
\end{pmatrix}.
\end{align*}

This way we reduce operations necessary for our algorithm from
operations over custom semiring (over edge labels) to operations over a Boolean semiring with an \term{addition} $+$ as $\lor$ and a \term{multiplication} $\cdot$ as $\land$ over Boolean values.

We also use notation $\mathcal{M}(\mathcal{G})$ and $\mathcal{G}(\mathcal{M})$ to describe the Boolean decomposition matrices for some graph and the graph formed by its adjacency Boolean matrices.

\begin{definition}
A \term{path} $\pi$ in the graph $\mathcal{G} = \langle V,E,L \rangle$ is a sequence $e_0,e_1,\ldots,e_{n-1}$, where $e_i = (v_i,l_i,u_i) \in E$ and for any $e_i, e_{i+1}$: $u_i = v_{i+1}$. We denote a path from $v$ to $u$ as $v\pi u$.
\end{definition}

\begin{definition}
A \term{word formed by a path} $$\pi = (v_0,l_0,v_1),(v_1,l_1,v_2),\ldots,(v_{n-1},l_{n-1},v_n)$$ is a concatenation of labels along the path: $\omega(\pi) = l_0 l_1 \ldots l_{n-1}$.
\end{definition}

\begin{definition}
A \term{language} $\mathcal{L}$ over a finite alphabet $\Sigma$ is a subset of all possible sequences formed by symbols from the alphabet: $\mathcal{L}_{\Sigma} = \{\omega \mid \omega \in \Sigma^*\}$.
\end{definition}

Now we are ready to introduce CFPQ problem for the given graph  $\mathcal{G} = \langle V,E,L \rangle$ and the given language $\mathcal{L}$ with reachability and all-path semantics.

\begin{definition}
To evaluate context-free path query with reachability semantics is to construct a set of pairs of vertices $(v_i,v_j)$ such that there exists a path $v_i \pi v_j$ in $\mathcal{G}$ which forms the word from the given language:
$$
R = \{(v_i,v_j) \mid \exists \pi: v_i \pi v_j, \omega(\pi) \in \mathcal{L} \}
$$
\end{definition}

\begin{definition}
To evaluate context-free path query with all-path semantics is to construct a set of paths $\pi$ in $\mathcal{G}$ which form the word from the given language:
$$
\Pi = \{ \pi \mid \omega(\pi) \in \mathcal{L}\}
$$
\end{definition}

Note that $\Pi$ can be infinite, thus in practice we should provide a way to enumerate such paths with reasonable complexity, instead of explicit construction of the $\Pi$.

\subsection{Regular Path Queries and Finite State Machine}

In \term{Regular Path Querying} (RPQ) the language $\mathcal{L}$ is regular.
This case is widespread and well-studied.
The most common way to specify regular languages is by \term{regular expressions}.
We use the following definition of regular expressions.
\begin{definition}
A \term{regular expression} over the alphabet $\Sigma$ is a finite combination of patterns, which can be defined as follows: $\varnothing$ (empty language), $\varepsilon$ (empty string), $a_i \in \Sigma$ are regular expressions, and if $R_1$ and $R_2$ are regular expressions, then $R_1 \mid R_2$ (alternation), $R_1 \cdot R_2$ (concatenation), $R_1^*$ (Kleene star) are also regular expressions.
\end{definition}

For example, one can use regular expression $R_1 = ab^*$ to search for paths in the graph $\mathcal{G}$ (Figure~\ref{fig:example_input_graph}).
The expected query result is a set of paths which start with an $a$-labeled edge and contain zero or more $b$-labeled edges after that.

In this work we use the notion of \term{Finite-State Machine} (FSM) or \term{Finite-State Automaton} (FSA) for RPQs.

\begin{definition}
A \term{deterministic finite-state machine without $\varepsilon$-transitions} $T$ is a tuple $\langle \Sigma, Q, Q_s, Q_f, \delta \rangle$, where $\Sigma$ is an input alphabet, $Q$ is a finite set of states, $Q_s \subseteq Q$ is a set of start (or initial) states, $Q_f \subseteq Q$ is a set of final states and $\delta: Q \times \Sigma \to Q$ is a transition function.
\end{definition}

It is well known, that every regular expression can be converted to deterministic FSM without $\varepsilon$-transitions~\cite{automata:theory:10.5555/1177300}.
We use FSM as a representation of RPQ.
FSM can be naturally represented by a directed edge-labeled graph: $V = Q$, $L = \Sigma$, $E = \{(q_i,l,q_j) \mid \delta(q_i,l) = q_j\}$, where some vertices have special markers to specify the start and final states.
An example of the graph representation of FSM $T_1$ for the regular expression $R_1$ is presented in Figure~\ref{fig:example_fsm}.

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[shorten >=1pt,auto]
       \node[state, initial] (q_0)                      {$0$};
       \node[state, accepting] (q_1) [right=of q_0] {$1$};
       \path[->]
        (q_0) edge  node {a} (q_1)
        (q_1) edge[loop right]  node {b} (q_1)
        ;
    \end{tikzpicture}
    \caption{The example of graph representation of FSM for the regular expression $ab^*$}
    \label{fig:example_fsm}
\end{figure}

As a result, FSM also can be represented as a set of Boolean adjacency matrices $\mathcal{M}$ accompanied by the information about the start and final vertices.
Such representation of $T_1$:
$$
M^a =
\begin{pmatrix}
0&1 \\
0&0
\end{pmatrix},~
M^b =
\begin{pmatrix}
0&0 \\
0&1
\end{pmatrix}.
$$

Note, that an edge-labeled graph can be viewed as an FSM where edges represent transitions, and all vertices are both start and final at the same time.
Thus RPQ evaluation is an intersection of two FSMs.
The query result can also be represented as FSM, because regular languages are closed under intersection.

\subsection{Context-Free Path Querying and Recursive State Machines}

An even more general case than RPQ is a \term{Context-Free Path Querying Problem (CFPQ)}, where one can use context-free languages as constraints.
These constraints are more expressive than the regular constraints.
For example, a classic same-generation query can be expressed by a context-free language, but not a regular language.

\begin{definition}
A \term{context-free grammar} $G = \langle\Sigma, N, S, P\rangle$, where $\Sigma$ is a finite set of terminals (or terminal alphabet), $N$ is a finite set of nonterminals (or nonterminal alphabet), $S \in N$ is a start nonterminal, $P$ is a finite set of productions (grammar rules) of form $N_i \to \alpha$ where  $N_i \in N$, $\alpha \in (\Sigma \cup N)^*$.
\end{definition}

\begin{definition}
The sequence $\omega_2 \in (\Sigma \cup N)^*$ is \term{derivable} from $\omega_1 \in (\Sigma \cup N)^*$ \term{in one derivation step}, or $\omega_1 \to \omega_2$, in the grammar $G = \langle\Sigma, N, S, P\rangle$ iff $\omega_1=\alpha N_i \beta$, $\omega_2 = \alpha \gamma \beta$, and $N_i \to \gamma \in P$.
\end{definition}

\begin{definition}
Context-free grammar $G=\langle\Sigma, N, S, P\rangle$ specifies a \term{context-free language}: $\mathcal{L}(G) = \{\omega \mid S \xrightarrow{*} \omega \}$, where $(\xrightarrow{*})$ denotes zero or more derivation steps $(\to)$.
\end{definition}

For instance, a grammar $G_1 = \langle \{a,b\}, \{S\}, S, \{S \to a \ b; \ S \to a \ S \ b\} \rangle$ can be used to search for paths, which form words in the language $\mathcal{L}(G_1) = \{a^n b^n \mid n > 0\}$ in the graph $\mathcal{G}$ (fig.~\ref{fig:example_input_graph}).

%Regular expressions can be transformed to a FSM, and a context free grammar can be transformed to \textit{Recursive State Machine} (RSM) (also known as recursive networks~\cite{!!!}, recursive automata~\cite{!!!}, !!!.) in the similar way.

% Ref to  Rajeev Alur, Kousha Etessami, and Mihalis Yannakakis. 2001.
% Analysis of Recursive State Machines place here???
While a regular expression can be transformed to a FSM, a context-free grammar can be transformed to a \term{Recursive State Machine} (RSM) in the similar fashion.
In our work we use the following definition of RSM based
on~\cite{rsm:analysis:10.1007/3-540-44585-4_18}.

\begin{definition}
A \term{recursive state machine} $R$ over a finite alphabet $\Sigma$ is defined as a tuple of elements $\langle M,m,\{C_i\}_{i \in M} \rangle$, where $M$ is a finite set of labels of boxes,
$m \in M$ is an initial box label, a $C_i=\langle \Sigma \cup M, Q_i,q_i^0,F_i,\delta_i \rangle$ is a \term{component state machine} or \term{box}, where:
    \begin{itemize}
        \item $\Sigma \cup M$ is a set of symbols, $\Sigma \cap M = \varnothing$
        \item $Q_i$ is a finite set of states,
              where $Q_i \cap Q_j = \varnothing, \forall i \neq j$
        \item $q_i^0$ is an initial state for $C_i$
        \item $F_i \subseteq Q_i$ is a set of the final states for $C_i$
        \item $\delta_i: Q_i \times (\Sigma \cup M) \to Q_i$ is a transition function %for $C_i$
    \end{itemize}

\end{definition}

RSM behaves as a set of finite state machines (or FSM).
Each FSM is called a \term{box} or a \term{component state machine}.
A box works similarly to the classical FSM, but it also handles additional \term{recursive calls} and employs an implicit \term{call stack} to \term{call} one component from another and then return execution flow back.

The execution of an RSM could be defined as a sequence of the configuration transitions, which are done while reading the input symbols.
The pair $(q_i,S)$, where $q_i$ is a current state for box $C_i$ and $S$ is  a stack of \term{return states}, describes an \term{execution configuration}.

The RSM execution starts from the configuration $(q_m^0, \langle\rangle)$.
The following list of rules defines the machine transition from configuration $(q_i,S)$ to $(q',S')$ on some input symbol $a$:
\begin{itemize}
    \item $(q_i^k,S) \leadsto (\delta_i (q_i^k, a),S)$
    \item $(q_i^k,S) \leadsto (q_j^0, \delta_i (q_i^k, j) \circ S)$
    \item $(q_j^k,q_i^t\circ S) \leadsto (q_i^t, S),$ where $q_j^k \in F_j$
\end{itemize}
    %\item $q' \gets q_j^0, S' \gets q_i^t \circ S$, where $q_i^t = \delta_i (q_i^k, j),  q_i^k = q, j \in M$
    %\item $q' \gets q_i^t, S' \gets S_{tail}$, where $S = q_i^t \circ S_{tail}, q_j^k = q, q_j^k \in F_j$

An input word $a_1 \dots a_n$ is accepted, if machine reaches configuration $(q,\langle\rangle)$, where $q \in F_m$.
Note, that an RSM makes nondeterministic transitions and does not read the input character when it \term{calls} some component or \term{returns}.

According to~\cite{rsm:analysis:10.1007/3-540-44585-4_18}, recursive state machines are equivalent to pushdown systems.
Since pushdown systems are capable of accepting context-free languages~\cite{automata:theory:10.5555/1177300}, RSMs are equivalent to context-free languages.
Thus RSMs suit to encode query grammars.
Any CFG can be easily converted to an RSM with one box per nonterminal.
The box which corresponds to a nonterminal $A$ is constructed using the right-hand side of each rule for $A$.

An example of such RSM $R$ constructed for the grammar $G$ with rules $S \to a S b \mid a b$ is provided in Figure~\ref{example:automata}.


Since $R$ is a set of FSMs, it can be represented as an adjacency matrix for the graph where vertices are states from $\bigcup_{i \in M}Q_i$ and edges are transitions between $q_i^a$ and $q_i^b$ with the label $l \in \Sigma \cup M$, if $\delta_i (q_i^a, l) = q_i^b$.
Thus, similarly to an FSM, an RSM can be represented as a set of Boolean adjacency matrices.

\begin{figure}[h]
    \begin{tikzpicture}[shorten >=1pt,auto]
        \node[state, initial] (q_0)   {$q_S^0$};
        \node[state] (q_1) [right=of q_0] {$q_S^1$};
        \node[state] (q_2) [right=of q_1] {$q_S^2$};
        \node[state, accepting] (q_3) [right=of q_2] {$q_S^3$};
        \path[->]
            (q_0) edge node {a} (q_1)
            (q_1) edge node {S} (q_2)
            (q_2) edge node {b} (q_3)
            (q_1) edge [bend left, above]  node {b} (q_3);
        \node (box) [draw=black, fit= (q_0) (q_1) (q_2) (q_3), xshift=-4ex, yshift=2ex, inner xsep=0.75cm, inner ysep=0.5cm] {};

        \node[draw=black, anchor=north west] at (box.north west) {Box $S$};
    \end{tikzpicture}
    \centering
    \caption{Recursive state machine $R$ for grammar $G$}
    \label{example:automata}
\end{figure}


As an RPQ, a CFPQ is the intersection of the given context-free language and a FSM specified by the given graph.
As far as every context-free language is closed under the intersection with regular languages, such intersection can be represented as an RSM.
Also, an RSM can be viewed as an FSM over $\Sigma \cup N$.
We use this point of view to propose a unified algorithm to evaluate both regular and context-free path queries with zero overhead for regular queries.

\subsection{Graph Kronecker Product and Machines Intersection}

In this section we introduce classical Kronecker product definition,
describe graph Kronecker product and its relation to Boolean matrices algebra,
and RSM and FSM intersection.

\begin{definition}
Given two matrices $A$ and $B$ of sizes $m_1 \times n_1$ and $m_2 \times n_2$
respectively, with element-wise product operation $\cdot$, the \term{Kronecker product} of these two matrices is a new matrix $C = A \otimes B$ of size $m_1 * m_2 \times n_1 * n_2$ and $C[u * m_1 + v,n_1 * p + q] = A[u,p] \cdot B[v,q]$.
\end{definition}

% (scalar to matrix)
\begin{definition}
\label{def:graph:product}
Given two edge-labeled directed graphs $\mathcal{G}_1=\langle V_1, E_1, L_1 \rangle$
and $\mathcal{G}_2=\langle V_2, E_2, L_2 \rangle$,
the \term{Kronecker product} of these graphs is a edge-labeled directed graph
$\mathcal{G}=\mathcal{G}_1 \otimes \mathcal{G}_2$,
where $\mathcal{G}= \langle V, E, L \rangle$:  $V = V_1 \times V_2$, $E = \{((u,v),l,(p,q)) \mid (u,l,p) \in E_1 \wedge (v,l,q) \in E_2 \}$ and $L = L_1 \cap L_2$.
\end{definition}

The Kronecker product for graphs produces a new graph with a property
that if some path $(u,v)\pi(p,q)$ exists in the result graph
then paths $u\pi_1p$ and $v\pi_2q$ exist in the input graphs,
and $\omega(\pi) = \omega(\pi_1) = \omega(\pi_2)$.
These paths $\pi_1$ and $\pi_2$ could be easily found from $\pi$ by its definition.

The Kronecker product for directed graphs can be described as
the Kronecker product of the corresponding adjacency matrices of graphs,
what gives the following definition:

\begin{definition}
Given two adjacency matrices $M_1$ and $M_2$ of sizes
$m_1 \times n_1$ and $m_2 \times n_2$ respectively
for some directed graphs $\mathcal{G}_1$ and $\mathcal{G}_2$,
the \term{Kronecker product} of these two adjacency matrices is the adjacency matrix $M$
of some graph $\mathcal{G}$, where $M$ has size $m_1 * m_2 \times n_1 * n_2$ and $M[u * m_1 + v,n_1 * p + q] = M_1[u,p] \cap M_2[v,q]$.
\end{definition}

By the definition, the Kronecker product for adjacency matrices gives an
adjacency matrix with the same set of edges as in the resulting graph in the
Def.~\ref{def:graph:product}. Thus, $M(\mathcal{G}) = M(\mathcal{G}_1) \otimes
M(\mathcal{G}_2)$, where $\mathcal{G} = \mathcal{G}_1 \otimes \mathcal{G}_2$.

\begin{definition}
\label{def:fsm:intersection}
Given two FSMs $T_1 = \langle \Sigma, Q^1, Q_S^1, S_F^1, \delta^1 \rangle$
and $T_2 = \langle \Sigma, Q^2, Q_S^2, S_F^2, \delta^2 \rangle$, the \term{intersection} of these two machines is a new FSM
$T = \langle \Sigma, Q, Q_S, S_F, \delta \rangle$, where $Q = Q^1 \times Q^2$, $Q_S = Q_S^1 \times Q_S^2$, $Q_F = Q_F^1 \times Q_F^2$, $\delta: Q \times \Sigma \to Q$ and $\delta (\langle q_1, q_2 \rangle, s) = \langle q_1', q_2' \rangle$, if $\delta(q_1,s)=q_1'$ and $\delta(q_2,s)=q_2'$.
\end{definition}

According to~\cite{automata:theory:10.5555/1177300} an FSM intersection defines the machine for which $L(T) = L(T_1) \cap L(T_2)$.

The most substantial part of intersection is the $\delta$ function construction for the new machine $T$.
Using adjacency matrices decomposition for FSMs, we can reduce the intersection to the Kronecker product of such matrices over Boolean semiring at some extent, since the transition function $\delta$ of the machine $T$ in matrix form is exactly the same as the product result.
More precisely:

\begin{definition}
\label{def:bool:product}
Given two adjacency matrices $\mathcal{M}_1$ and $\mathcal{M}_2$ over Boolean semiring, the \term{Kronecker product} of these matrices is a new matrix
$\mathcal{M} = \mathcal{M}_1 \otimes \mathcal{M}_2$, where $\mathcal{M} = \{ M_1^a \otimes M_2^a~|~a \in \Sigma \}$ and the element-wise operation is \term{and} over Boolean values.

\end{definition}

Applying the Kronecker product theory for both the FSM and the edge-labeled directed graph, we can intersect these objects as shown in Def.~\ref{def:bool:product}, since the graph could be interpreted as an FSM with transitions matrix represented as the Boolean adjacency matrix.

In this work we show how to express RSM and FSM intersection in terms of
the Kronecker product and transitive closure over Boolean semiring.