\section{Evaluation}

While our project\footnote{GraphBLAS\# project page: \url{https://github.com/YaccConstructor/GraphBLAS-sharp}. Access date: 08.01.2023.} is in a very early stage we implemented and evaluated only generic matrix-matrix element-wise function \texttt{map2} to demonstrate that the proposed solution may provide not only a way to an expressive compact high-level API, but also a way to its high-performance implementation. This function is implemented for matrices in CSR format. We use Brahma.FSharp to support GPGPUs.  

We evaluated \texttt{map2} function parameterized by two operations: \texttt{op\_int\_add} (listing~\ref{lst:opIntAdd}) to get element-wise addition in terms of GraphBLAS API, and \texttt{op\_int\_mult} (listing~\ref{lst:opIntMult}) to get element-wise multiplication.

\subsection{Environment}
We perform our experiments on the PC with Ubuntu 20.04 installed and with the following hardware configuration: Intel Core i7--4790 CPU, 3.60GHz, 32GB DDR4 RAM with GeForce GTX 2070, 8GB GDDR6, 1.41GHz.

For comparison we choose a SuiteSparse:GraphBLAS as a reference CPU implementation of GraphBLAS API, and CUSP\footnote{Cusp is a CUDA-based library for sparse linear algebra and graph computations: \url{https://cusplibrary.github.io/}. Access date: 08.01.2023.} as a most stable GPGPU implementation of generic sparse linear algebra.

\begin{table}[H]
    \centering
    \caption{Matrices for evaluation}
    \label{matrices}  
    \begin{tabular}{ | c || c | c | >{\centering\arraybackslash}p{2cm} | }
    \hline
    Matrix & Size & NNZ & Squared mtx NNZ \\ \hline
    \hline
    wing & 62 032 & 243 088 & 714 200 \\ \hline
    luxembourg\_osm & 114 599 & 119 666 & 393 261 \\ \hline
    amazon0312 & 400 727 & 3 200 440 & 14 390 544 \\ \hline
    amazon-2008 & 735 323 & 5 158 388 & 25 366 745 \\ \hline
    web-Google & 916 428 & 5 105 039 & 29 710 164 \\ \hline
    webbase-1M & 1 000 005 & 3 105 536 & 51 111 996 \\ \hline
    cit-Patents & 3 774 768 & 16 518 948 & 469 \\ \hline
    \end{tabular}
\end{table}


\subsection {Dataset}

For evaluation we selected a set of matrices from SuiteSparse matrix collection\footnote{SuiteSparse matrix collection: \url{https://sparse.tamu.edu/}. Access date: 08.01.2023.}
To simplify the evaluation of element-wise operations over matrices with different structures we precomputed the square of each matrix.
Characteristics of selected matrices are presented in table~\ref{matrices}.

\subsection{Evaluation Results}

\begin{table*}[h]
    \centering    
    \caption{Evaluation results for element-wise operations, time in ms}    
    \label{perf-comparison-add}
    \begin{tabular}{|c||c|c|c|c|}
    \hline
    \multirow{3}{*}{Matrix} & \multicolumn{4}{c|}{Elemint-wise addition}\\    
    \cline{2-5}        
    & \multicolumn{2}{c|}{GraphBLAS-sharp} & \multirow{2}{*}{SuiteSparse} & \multirow{2}{*}{CUSP} \\
    &No \texttt{AtLeastOne}&\texttt{AtLeastOne}& & \\ 
    \hline
    \hline
    wing            & $4,3 \pm 0,8$       & $4,3 \pm 0,6$      & $2,7\pm 0,9$   & $1,5\pm 0,0$     \\
    \hline
    luxembourg\_osm & $4,9 \pm 0,7$       & $4,1 \pm 0,5$      & $3,0\pm 1,1$   & $1,2\pm 0,1$     \\
    \hline
    amazon0312      & $22,3 \pm 1,3$       & $22,1 \pm 1,3$      & $33,4\pm 0,8$  & $11,0\pm 1,4$  \\
    \hline
    amazon-2008     & $38,7 \pm 0,8$       & $39,0 \pm 1,0$     & $55,9\pm 1,0$  & $19,1\pm 1,4$   \\
    \hline
    web-Google      & $43,4 \pm 0,8$       & $43,4 \pm 1,1$     & $67,2\pm 7,5$  & $21,3\pm 1,3$   \\
    \hline
    webbase-1M      & $63,6 \pm 1,1$      & $63,7 \pm 1,3$      & $86,5\pm 2,0$  & $24,3\pm 1,3$   \\
    \hline
    cit-Patents     & $26,9 \pm 0,7$      & $26,0 \pm 0,7$      & $183,4\pm 5,4$ & $10,8\pm 0,6$   \\     
    \hline
    \end{tabular}    
\end{table*}

\begin{table*}[h]
    \centering    
    \caption{Evaluation results for element-wise operations, time in ms}    
    \label{perf-comparison-mult}
    \begin{tabular}{|c||c|c|}
    \hline
    \multirow{2}{*}{Matrix} & \multicolumn{2}{c|}{Elemint-wise multiplication}\\    
    \cline{2-3}        
    &  {GraphBLAS-sharp} & {SuiteSparse}        \\    
    \hline
    \hline
    wing            & $3,7 \pm 0,5$      & $3,5\pm 0,4$\\
    \hline
    luxembourg\_osm & $3,8 \pm 0,6$      & $3,0\pm 0,6$ \\
    \hline
    amazon0312      & $18,7 \pm 0,9$      & $35,7\pm 1,4$ \\
    \hline
    amazon-2008     & $34,5 \pm 1,0$     & $58,9\pm 1,9$  \\
    \hline
    web-Google      & $39,0 \pm 1,2$     & $66,2\pm 0,4$ \\
    \hline
    webbase-1M      & $54,5 \pm 0,7$      & $37,6\pm 5,6$ \\
    \hline
    cit-Patents     & $24,3 \pm 0,7$      & $162,2\pm 1,7$ \\
    \hline
    \end{tabular}    
\end{table*}

To benchmark a .NET-based implementation we use \textit{BenchmarkDotNet}\footnote{\textit{BenchmarkDotNet}: \url{https://benchmarkdotnet.org/}. Access date: 08.01.2023.} which allows one to automate benchmarking process for .NET platform.
We run each function 100 times, separated warm up runs were added for our implementation. 
Time is measured in milliseconds. Time to prepare data and initially transfer it to GPU is not included.

Results of performance evaluation are presented in tables~\ref{perf-comparison-add} and~\ref{perf-comparison-mult}.
For element-wise addition, our implementation is slightly slower than SuiteSparse:GraphBLAS for small matrices (\textbf{wing, luxembourg\_osm}) and up to 7 times faster for big matrices (1.5 times in median). At the same time our implementation is 2.5 times slower than CUSP-based. Note that CUSP is based on the highly-optimized Thrust library. For element-wise multiplication comparison with SuiteSparse:GraphBLAS shows almost similar results except matrix \textbf{webbase-1M} for which our implementation is slower than SuiteSparse:GraphBLAS.

Comparison between original element-wise addition over primitive types without \texttt{AtLeasOne} and generalized version which uses \texttt{AtLeastOne} type is also presented in table~\ref{perf-comparison-add}.
We can see that more complex data types and element-wise operations do not poor performance of matrix-matrix operations because data transfer dominates arithmetic computations for sparse matrix processing, and the proposed abstraction does not increase the memory footprint.