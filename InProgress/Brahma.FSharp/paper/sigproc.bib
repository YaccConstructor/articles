@book{fsharp,
  title={Expert F\# 3.0},
  author={Syme, Don and Granicz, Adam and Cisternino, Antonio},
  year={2012},
  publisher={Springer}
}

@phdthesis{FSCLPhD,
  title={Homogeneous programming, scheduling and execution on heterogeneous platforms},
  author={Coco, G},
  year={2014},
  school={Ph. D. Thesis.$\backslash$Gabriel Coco.-University of Pisa, 2014.-254 p}
}


@phdthesis{BrahmaStringMatching,
  title={Transparent usage of massively parallel architectures for local optimizations of .NET applications},
  author={Mikhaylov, Dmitry},
  year={2013},
  school={Graduation Thesis.$\backslash$Dmitry Mikhaylov.-St. Petersburg State University, 2013.-47 p}
}

@inproceedings{aleaGPUasync,
  title={The alea reactive dataflow system for gpu parallelization},
  author={Kramer, Philipp and Egloff, Daniel and Blaser, L},
  booktitle={Proc. of the HLGPU 2016 Workshop, HiPEAC},
  year={2016}
}

@inproceedings{aleaGPUasync2,
  title={Alea Reactive Dataflow: GPU Parallelization Made Simple},
  author={Bl{\"a}ser, Luc and Egloff, Daniel and Knobel, Oskar and Kramer, Philipp and Zhang, Xiang and Fabian, Daniel},
  booktitle={Proceedings of the companion publication of the 2014 ACM SIGPLAN conference on Systems, Programming, and Applications: Software for Humanity},
  year={2014}
}

@misc{AleaGPU,
  author = {{QuanAlea Inc}},
  title = {Alea GPU},
  howpublished = {\url{https://www.quantalea.net/}},
  note = {Accessed: 2017-06-20}
}

@misc{CUDA,
  author = {{Nvidia Inc}},
  title = {CUDA C Programming Guide. Version 8.0},
  howpublished = {\url{http://docs.nvidia.com/cuda/cuda-c-programming-guide}},
  note = {Accessed: 2017-06-20}
}

@misc{OpenCL,
  author = {{Khronos Group}},
  title = {The Open Standard for Parallel Programming of Heterogeneous Systems. OpenCL 2.2},
  howpublished = {\url{https://www.khronos.org/opencl/}},
  note = {Accessed: 2017-06-20}
}

@inproceedings{jcuda,
  title={JCUDA: A programmer-friendly interface for accelerating Java programs with CUDA},
  author={Yan, Yonghong and Grossman, Max and Sarkar, Vivek},
  booktitle={European Conference on Parallel Processing},
  pages={887--899},
  year={2009},
  organization={Springer}
}

@inproceedings{HaskellGPU,
  title={Obsidian: A domain specific embedded language for parallel programming of graphics processors},
  author={Svensson, Joel and Sheeran, Mary and Claessen, Koen},
  booktitle={Symposium on Implementation and Application of Functional Languages},
  pages={156--173},
  year={2008},
  organization={Springer}
}

@inproceedings{rootbeer,
  title={Rootbeer: Seamlessly using gpus from java},
  author={Pratt-Szeliga, Philip C and Fawcett, James W and Welch, Roy D},
  booktitle={High Performance Computing and Communication \& 2012 IEEE 9th International Conference on Embedded Software and Systems (HPCC-ICESS), 2012 IEEE 14th International Conference on},
  pages={375--380},
  year={2012},
  organization={IEEE}
}

@inproceedings{ScalaGPU,
  title={Firepile: run-time compilation for GPUs in scala},
  author={Nystrom, Nathaniel and White, Derek and Das, Kishen},
  booktitle={ACM SIGPLAN Notices},
  volume={47},
  number={3},
  pages={107--116},
  year={2011},
  organization={ACM}
}

@inproceedings{RustGPU,
  title={GPU programming in rust: implementing high-level abstractions in a systems-level language},
  author={Holk, Eric and Pathirage, Milinda and Chauhan, Arun and Lumsdaine, Andrew and Matsakis, Nicholas D},
  booktitle={Parallel and Distributed Processing Symposium Workshops \& PhD Forum (IPDPSW), 2013 IEEE 27th International},
  pages={315--324},
  year={2013},
  organization={IEEE}
}

@inproceedings{FSharpAsync,
  title={The F\# asynchronous programming model},
  author={Syme, Don and Petricek, Tomas and Lomov, Dmitry},
  booktitle={International Symposium on Practical Aspects of Declarative Languages},
  pages={175--189},
  year={2011},
  organization={Springer}
}

@inproceedings{FSharpQuotations,
  title={Leveraging. net meta-programming components from f\#: integrated queries and interoperable heterogeneous execution},
  author={Syme, Don},
  booktitle={Proceedings of the 2006 workshop on ML},
  pages={43--54},
  year={2006},
  organization={ACM}
}

@article{FSharpTypeProvider1,
  title={Strongly-typed language support for internet-scale information sources},
  author={Syme, Don and Battocchi, Keith and Takeda, Kenji and Malayeri, Donna and Fisher, Jomo and Hu, Jack and Liu, Tao and McNamara, Brian and Quirk, Daniel and Taveggia, Matteo and others},
  journal={Technical Report MSR-TR-2012--101, Microsoft Research},
  year={2012}
}
@article{FSharpTypeProvider2,
  title={F\# Data: Making structured data first class citizens},
  author={Petricek, Tomas and Guerra, Gustavo and Syme, Don},
  journal={Submitted to ICFP},
  volume={2015},
  year={2015}
}

@inproceedings{10.1145/3062341.3062354,
author = {Henriksen, Troels and Serup, Niels G. W. and Elsman, Martin and Henglein, Fritz and Oancea, Cosmin E.},
title = {Futhark: purely functional GPU-programming with nested parallelism and in-place array updates},
year = {2017},
isbn = {9781450349888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3062341.3062354},
doi = {10.1145/3062341.3062354},
abstract = {Futhark is a purely functional data-parallel array language that offers a machine-neutral programming model and an optimising compiler that generates OpenCL code for GPUs.  This paper presents the design and implementation of three key features of Futhark that seek a suitable middle ground with imperative approaches.  First, in order to express efficient code inside the parallel constructs, we introduce a simple type system for in-place updates that ensures referential transparency and supports equational reasoning.  Second, we furnish Futhark with parallel operators capable of expressing efficient strength-reduced code, along with their fusion rules.  Third, we present a flattening transformation aimed at enhancing the degree of parallelism that (i) builds on loop interchange and distribution but uses higher-order reasoning rather than array-dependence analysis, and (ii) still allows further locality-of-reference optimisations. Finally, an evaluation on 16 benchmarks demonstrates the impact of the language and compiler features and shows application-level performance competitive with hand-written GPU code.},
booktitle = {Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {556–571},
numpages = {16},
keywords = {parallel, functional language, compilers, GPGPU},
location = {Barcelona, Spain},
series = {PLDI 2017}
}

@article{10.1145/3140587.3062354,
author = {Henriksen, Troels and Serup, Niels G. W. and Elsman, Martin and Henglein, Fritz and Oancea, Cosmin E.},
title = {Futhark: purely functional GPU-programming with nested parallelism and in-place array updates},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/3140587.3062354},
doi = {10.1145/3140587.3062354},
abstract = {Futhark is a purely functional data-parallel array language that offers a machine-neutral programming model and an optimising compiler that generates OpenCL code for GPUs.  This paper presents the design and implementation of three key features of Futhark that seek a suitable middle ground with imperative approaches.  First, in order to express efficient code inside the parallel constructs, we introduce a simple type system for in-place updates that ensures referential transparency and supports equational reasoning.  Second, we furnish Futhark with parallel operators capable of expressing efficient strength-reduced code, along with their fusion rules.  Third, we present a flattening transformation aimed at enhancing the degree of parallelism that (i) builds on loop interchange and distribution but uses higher-order reasoning rather than array-dependence analysis, and (ii) still allows further locality-of-reference optimisations. Finally, an evaluation on 16 benchmarks demonstrates the impact of the language and compiler features and shows application-level performance competitive with hand-written GPU code.},
journal = {SIGPLAN Not.},
month = jun,
pages = {556–571},
numpages = {16},
keywords = {parallel, functional language, compilers, GPGPU}
}

@inproceedings{10.5555/3049832.3049841,
author = {Steuwer, Michel and Remmelg, Toomas and Dubach, Christophe},
title = {Lift: a functional data-parallel IR for high-performance GPU code generation},
year = {2017},
isbn = {9781509049318},
publisher = {IEEE Press},
abstract = {Parallel patterns (e.g., map, reduce) have gained traction as an abstraction for targeting parallel accelerators and are a promising answer to the performance portability problem. However, compiling high-level programs into efficient low- level parallel code is challenging. Current approaches start from a high-level parallel IR and proceed to emit GPU code directly in one big step. Fixed strategies are used to optimize and map parallelism exploiting properties of a particular GPU generation leading to performance portability issues.  We introduce the Lift IR, a new data-parallel IR which encodes OpenCL-specific constructs as functional patterns. Our prior work has shown that this functional nature simplifies the exploration of optimizations and mapping of parallelism from portable high-level programs using rewrite-rules.  This paper describes how Lift IR programs are compiled into efficient OpenCL code. This is non-trivial as many performance sensitive details such as memory allocation, array accesses or synchronization are not explicitly represented in the Lift IR. We present techniques which overcome this challenge by exploiting the pattern’s high-level semantics. Our evaluation shows that the Lift IR is flexible enough to express GPU programs with complex optimizations achieving performance on par with manually optimized code.},
booktitle = {Proceedings of the 2017 International Symposium on Code Generation and Optimization},
pages = {74–85},
numpages = {12},
location = {Austin, USA},
series = {CGO '17}
}


@article{10.1145/3276489,
author = {Lei\ss{}a, Roland and Boesche, Klaas and Hack, Sebastian and P\'{e}rard-Gayot, Ars\`{e}ne and Membarth, Richard and Slusallek, Philipp and M\"{u}ller, Andr\'{e} and Schmidt, Bertil},
title = {AnyDSL: a partial evaluation framework for programming high-performance libraries},
year = {2018},
issue_date = {November 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {OOPSLA},
url = {https://doi.org/10.1145/3276489},
doi = {10.1145/3276489},
abstract = {This paper advocates programming high-performance code using partial evaluation. We present a clean-slate programming system with a simple, annotation-based, online partial evaluator that operates on a CPS-style intermediate representation. Our system exposes code generation for accelerators (vectorization/parallelization for CPUs and GPUs) via compiler-known higher-order functions that can be subjected to partial evaluation. This way, generic implementations can be instantiated with target-specific code at compile time.  In our experimental evaluation we present three extensive case studies from image processing, ray tracing, and genome sequence alignment. We demonstrate that using partial evaluation, we obtain high-performance implementations for CPUs and GPUs from one language and one code base in a generic way. The performance of our codes is mostly within 10\%, often closer to the performance of multi man-year, industry-grade, manually-optimized expert codes that are considered to be among the top contenders in their fields.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {119},
numpages = {30},
keywords = {GPU computing, high-performance, library design, parallelization, partial evaluation, vectorization}
}

@inproceedings{10.1145/1926354.1926358,
author = {Chakravarty, Manuel M.T. and Keller, Gabriele and Lee, Sean and McDonell, Trevor L. and Grover, Vinod},
title = {Accelerating Haskell array codes with multicore GPUs},
year = {2011},
isbn = {9781450304863},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1926354.1926358},
doi = {10.1145/1926354.1926358},
abstract = {Current GPUs are massively parallel multicore processors optimised for workloads with a large degree of SIMD parallelism. Good performance requires highly idiomatic programs, whose development is work intensive and requires expert knowledge.To raise the level of abstraction, we propose a domain-specific high-level language of array computations that captures appropriate idioms in the form of collective array operations. We embed this purely functional array language in Haskell with an online code generator for NVIDIA's CUDA GPGPU programming environment. We regard the embedded language's collective array operations as algorithmic skeletons; our code generator instantiates CUDA implementations of those skeletons to execute embedded array programs.This paper outlines our embedding in Haskell, details the design and implementation of the dynamic code generator, and reports on initial benchmark results. These results suggest that we can compete with moderately optimised native CUDA code, while enabling much simpler source programs.},
booktitle = {Proceedings of the Sixth Workshop on Declarative Aspects of Multicore Programming},
pages = {3–14},
numpages = {12},
keywords = {arrays, data parallelism, dynamic compilation, gpgpu, haskell, skeletons},
location = {Austin, Texas, USA},
series = {DAMP '11}
}