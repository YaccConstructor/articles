\section{Introduction}

Last decades, the utilization of GPGPUs has become more popular not only in scientific or dedicated applications, but also in regular business applications.
In such cases, the focus has shifted from peak performance to transparent offloading of computations to accelerators.
As a result, respective tools for integration of GPGPUs into platforms such as the JVM~\cite{rootbeer,jcuda,ScalaGPU} or .NET~\cite{FSCLPhD,aleaGPUasync} have been developed.
Note that in real-world applications, the problem is not only to offload computations to GPGPUs, but also to orchestrate heterogeneous asynchronous applications that may involve computations on several GPGPUs.

At the same time, the utilization of existing functional languages and creation of new ones for GPGPU programming looks promising due to their safety, flexibility, ability to use advanced optimization techniques, and capacity to create high-level abstractions. 
This has led to projects such as Futhark~\cite{10.1145/3140587.3062354}, Lift~\cite{10.5555/3049832.3049841}, AnyDSL~\cite{10.1145/3276489}, and Accelerate~\cite{10.1145/1926354.1926358}.

Currently, there are very few combinations of mature business application development platforms and functional programming languages.
One of them is the .NET platform with the F\# programming language.
There are several tools, such as Alea GPU~\cite{aleaGPUasync}, FCSL~\cite{FSCLPhD}, and ILGPU\footnote{ILGPU project web page: \url{https://ilgpu.net/}}, that enable integration of GPGPUs into .NET applications without using unsafe and low-level mechanisms like string-level kernel creation.
While FSCL and Alea GPU use F\# to create kernels, ILGPU works at the IL level, which limits the ability to use high-level features and non-trivial optimizations.

Alea GPU specifically targets CUDA-only environments, focusing on HPC and machine learning workloads through existing CUDA libraries.
This design inherently prevents support for non-NVIDIA GPUs, including a wide range of low-power devices. 
FCSL---an F\# to OpenCL translator---originates from a research project primarily investigating automatic computation scheduling in heterogeneous systems.
Despite useful features like automatic caching of compile kernels and an extensible compiler framework, it abstracts away certain low-level details that are critical for performance tuning, including parameter binding specifics, memory allocation control, and other optimization-related configurations.


In this work, we propose \textbf{Brahma.FSharp}\footnote{
    Sources of Brahma.FSharp: \url{https://github.com/YaccConstructor/Brahma.FSharp}
}---a tool for portable GPGPU-enabled .NET application development that provides transparent and safe integration with accelerators---and demonstrate its portability across a variety of platforms and devices.